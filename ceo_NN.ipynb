{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaidKaawach/ebuyer-scraper/blob/master/ceo_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdMyRtFP_eRm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c6ac5db-6ace-4ab8-8ee7-67b29d80f01d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive #library required if the data to import is located on the drive\n",
        "drive.mount('/content/drive') # Mount function of above library enables to read the data from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPq-cPpmCel-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  #imported for the reading the csv dataset\n",
        "import numpy as np #import for mathematical operations\n",
        "from sklearn.model_selection import train_test_split #imported for spliting the dataset\n",
        "import matplotlib.pyplot as plt # imported for visualizing the results\n",
        "from sklearn.metrics import classification_report # imported for creating the classification report\n",
        "\n",
        "df = pd.read_csv(\"drive/MyDrive/senators.csv\",encoding=\"ISO-8859-1\") # importing Senator dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78XYIy5kDDof"
      },
      "source": [
        "# Visualizing the data in Terms of classes distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSG8jsaVBUnH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "b48ea5eb-a660-4a73-b192-39d2c012e385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Party                                              Tweet     Handle\n",
            "0     D  On #MemorialDay, we salute all who have bravel...  AlmaAdams\n",
            "1     D  On #MemorialDay, we remember the brave men and...  AlmaAdams\n",
            "2     D  RT @shmetrolina: We are closed today, May 30th...  AlmaAdams\n",
            "3     D  RT @NCDOT: All #NCDMV offices are closed today...  AlmaAdams\n",
            "4     D  RT @TSUedu: Never forget <U+0001F499><U+0001F9...  AlmaAdams\n",
            "The Total Number of Class: 2\n",
            "The Samples Per class:\n",
            " D    640548\n",
            "R    408027\n",
            "Name: Party, dtype: int64\n",
            "The Diagram Shows Below the histogram of class distribution.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<AxesSubplot:title={'center':'Party_Numeric_Class'}>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaxElEQVR4nO3dfZRdVZ3m8e8jAY3hJUC0pJNA6Ca+RDIo1pDYTtul0VBgt6HX2HQY6CQMTdYIOIzQtnFmlmlhmAXTg2iUAWMTE2g0ZPAltQRMx8gdWqcDCYNNeJGhOgRTMRBMSELxHvjNH2eXcynvrrp1q+rcqtTzWeuuOvd39jl771vhPnVe7kURgZmZWS1vavYAzMxs5HJImJlZlkPCzMyyHBJmZpblkDAzsyyHhJmZZTkkzEYBSX8g6bFh7iMknTScfdjo45CwppC0TdKLkrolPS1ppaTDG9hPRdJfDNF4dkmaUFX7C0mVwe57KETEP0TEuwazD0nHSbpJ0k5Jz0n6haQvVc/ZrDeHhDXTH0fE4cCpQCvwn+vdUIWh/vd7CHDpEO9z0CSNG4J9HAP8IzAe+GBEHAF8HJgI/N5g928HL4eENV1E7ADuAmZK+qGkZyQ9m5an9LRLRw1XSfoZ8AJwC/AHwNfTEcnXJV0v6drq/UvqkPTZOobyN8BfSprYe4Wkael0zLiq2m+OYiQtkvQzSddJ2itpq6TfT/Xt6ShlYdW2b5b03yX9Mh1J3ShpfFrXJqlL0uclPQV8q6dWtf1USd9Lr9VuSV/vZ26XAc8B50XEtvS6b4+ISyPiwRrz/YSkByTtT+P/66p1b5H0d6nfvZI2SWqpeh22piOVJySd2//LbiOZQ8KaTtJU4ExgK/At4ATgeOBFoPeb358Di4EjgEXAPwCXRMThEXEJsAo4p+coQ9Ik4GPAt+sYymagAvxlg1OZBTwIHJv6Ww38S+Ak4DyKMOs5pXY18E7gfWn9ZOCLVft6B3AMxWuxuLoTSYcAPwSeBKalbVf3M7aPAd+LiNfrnMvzwAKKI41PAJ+WdFZatxA4Cpia5vrvgBfTaatlwBnpSOX3gZ/X2Z+NUA4Ja6YfSNoL/BT4X8BfRcR3I+KFiHgOuAr4w17brIyIhyPiQES82nuHEXEfsA+Yk0rzgUpEPF3nmL4IfEbS2xqYzxMR8a2IeA24jeJN9IqIeDki/h54BThJkije+D8bEXvSXP9rGmuP14GladsXe/VzGvA7wOci4vmIeCkiftrP2I4FdtY7kYioRMSWiHg9HWl8h///u3g17e+kiHgtIu6PiP1V4z5Z0viI2BkRD9fbp41MDglrprMiYmJEnBARF1FcaviGpCcl7QfuASamv5x7bK9jv6so/nIn/byl3gFFxEMUf6UvqXebKtVB9GLaX+/a4cDbgLcC96fTNXuBH6V6j2ci4qVMP1OBJyPiwADGths4rt7GkmZJujudztpHcbQwKa2+BVgHrJb0K0n/TdKhEfE88Gep7U5Jd0h69wDGaCOQQ8JGksuBdwGzIuJI4MOprqo2vb+2uNbXGP8dME/SKcB7gB8McBxLgQspTuP0eD79fGtV7R0D3G+PX1MExntTSE6MiKPSRfwefX0983bg+AFe0P4x8CcDuNj/baADmBoRRwE3kn4PEfFqRHwpImZQnFL6I4pTU0TEuoj4OEUg/QL45gDGaCOQQ8JGkiMo3jz3prtxltaxzdPA71YXIqIL2ETxF+93a5yu6VNEdFKcLvr3VbVngB3AeZIOkfRvafCuoHRd4JvAdZLeDiBpsqTT69zFfRSnjq6WNCFdSP5QP9t8GTgSWCXphKo+vyzpX9RofwSwJyJeknQa8G96Vkj6iKSZ6QhvP8Xpp9cltUial65NvAx0U5x+slHMIWEjyVcobtH8NbCR4hRMf74KfCrdDbWsqr4KmMkATjX1cgXQ+/MDFwKfozh1817gfze4b4DPA53AxnRq7ccUR1H9Stc8/pjigvcvgS6K0zx9bbOH4q/+V4F7JT0HbKC4ftNZY5OLgCtSuy8Ca6rWvQO4nSIgHqW4nnQLxfvJZcCvgD0U1zA+Xc+cbOSS/6dDdjCS9GGK004nhP+RmzXMRxJ20JF0KMWH4v7WAWE2OA4JO6hIeg+wl+LC6Veq6senD9zVehzfpOEOqfSBvFrzu7HZY7PRy6ebzMwsy0cSZmaWNegvDhtpJk2aFNOmTWto2+eff54JE8bWF2J6zmOD53zwG+x877///l9HxG9908BBFxLTpk1j8+bNDW1bqVRoa2sb2gGNcJ7z2OA5H/wGO19JT9aq+3STmZllOSTMzCzLIWFmZlkOCTMzy3JImJlZlkPCzMyyHBJmZpblkDAzsyyHhJmZZR10n7g2M2umaUvuaEq/K9uH5ytIfCRhZmZZDgkzM8tySJiZWZZDwszMshwSZmaW5ZAwM7Msh4SZmWU5JMzMLMshYWZmWXWFhKSJkm6X9AtJj0r6oKRjJK2X9Hj6eXRqK0nLJHVKelDSqVX7WZjaPy5pYVX9A5K2pG2WSVKq1+zDzMzKUe+RxFeBH0XEu4FTgEeBJcCGiJgObEjPAc4ApqfHYuAGKN7wgaXALOA0YGnVm/4NwIVV27Wneq4PMzMrQb8hIeko4MPATQAR8UpE7AXmAatSs1XAWWl5HnBzFDYCEyUdB5wOrI+IPRHxLLAeaE/rjoyIjRERwM299lWrDzMzK0E9X/B3IvAM8C1JpwD3A5cCLRGxM7V5CmhJy5OB7VXbd6VaX/WuGnX66OMNJC2mOGqhpaWFSqVSx7R+W3d3d8Pbjlae89jgOZfn8pkHSu8Thm++9YTEOOBU4DMRca+kr9LrtE9EhKQY8tHV2UdELAeWA7S2tkZbW1tDfVQqFRrddrTynMcGz7k8i5r4LbDDMd96rkl0AV0RcW96fjtFaDydThWRfu5K63cAU6u2n5JqfdWn1KjTRx9mZlaCfkMiIp4Ctkt6VyrNAR4BOoCeO5QWAmvTcgewIN3lNBvYl04ZrQPmSjo6XbCeC6xL6/ZLmp3ualrQa1+1+jAzsxLU+z8d+gxwq6TDgK3A+RQBs0bSBcCTwNmp7Z3AmUAn8EJqS0TskXQlsCm1uyIi9qTli4CVwHjgrvQAuDrTh5mZlaCukIiInwOtNVbNqdE2gIsz+1kBrKhR3wycXKO+u1YfZmZWDn/i2szMshwSZmaW5ZAwM7Msh4SZmWU5JMzMLMshYWZmWQ4JMzPLckiYmVmWQ8LMzLIcEmZmluWQMDOzLIeEmZllOSTMzCzLIWFmZlkOCTMzy3JImJlZlkPCzMyyHBJmZpblkDAzsyyHhJmZZTkkzMwsyyFhZmZZDgkzM8uqKyQkbZO0RdLPJW1OtWMkrZf0ePp5dKpL0jJJnZIelHRq1X4WpvaPS1pYVf9A2n9n2lZ99WFmZuUYyJHERyLifRHRmp4vATZExHRgQ3oOcAYwPT0WAzdA8YYPLAVmAacBS6ve9G8ALqzarr2fPszMrASDOd00D1iVllcBZ1XVb47CRmCipOOA04H1EbEnIp4F1gPtad2REbExIgK4ude+avVhZmYlGFdnuwD+XlIA34iI5UBLROxM658CWtLyZGB71bZdqdZXvatGnT76eANJiymOWmhpaaFSqdQ5rTfq7u5ueNvRynMeGzzn8lw+80DpfcLwzbfekPhXEbFD0tuB9ZJ+Ub0yIiIFyLDpq48UWssBWltbo62traE+KpUKjW47WnnOY4PnXJ5FS+4ovU+Ale0ThmW+dZ1uiogd6ecu4PsU1xSeTqeKSD93peY7gKlVm09Jtb7qU2rU6aMPMzMrQb8hIWmCpCN6loG5wENAB9Bzh9JCYG1a7gAWpLucZgP70imjdcBcSUenC9ZzgXVp3X5Js9NdTQt67atWH2ZmVoJ6Tje1AN9Pd6WOA74dET+StAlYI+kC4Eng7NT+TuBMoBN4ATgfICL2SLoS2JTaXRERe9LyRcBKYDxwV3oAXJ3pw8zMStBvSETEVuCUGvXdwJwa9QAuzuxrBbCiRn0zcHK9fZiZWTn8iWszM8tySJiZWZZDwszMshwSZmaW5ZAwM7Msh4SZmWU5JMzMLMshYWZmWQ4JMzPLckiYmVmWQ8LMzLIcEmZmluWQMDOzLIeEmZllOSTMzCzLIWFmZlkOCTMzy3JImJlZlkPCzMyyHBJmZpblkDAzsyyHhJmZZTkkzMwsq+6QkHSIpAck/TA9P1HSvZI6Jd0m6bBUf3N63pnWT6vaxxdS/TFJp1fV21OtU9KSqnrNPszMrBzjBtD2UuBR4Mj0/BrguohYLelG4ALghvTz2Yg4SdL81O7PJM0A5gPvBX4H+LGkd6Z9XQ98HOgCNknqiIhH+uhjWGzZsY9FS+4Yrt1nbbv6E6X3aWZWj7qOJCRNAT4B/G16LuCjwO2pySrgrLQ8Lz0nrZ+T2s8DVkfEyxHxBNAJnJYenRGxNSJeAVYD8/rpw8zMSlDvkcRXgL8CjkjPjwX2RsSB9LwLmJyWJwPbASLigKR9qf1kYGPVPqu32d6rPqufPt5A0mJgMUBLSwuVSqXOab1Ry3i4fOaB/hsOsUbHOxS6u7ub2n8zeM5jQ7Pm3Iz3EBi++fYbEpL+CNgVEfdLahvyEQyBiFgOLAdobW2Ntra2hvbztVvXcu2WgZyBGxrbzm0rvc8elUqFRl+v0cpzHhuaNedmnLIGWNk+YVjmW8874oeAT0o6E3gLxTWJrwITJY1Lf+lPAXak9juAqUCXpHHAUcDuqnqP6m1q1Xf30YeZmZWg32sSEfGFiJgSEdMoLjz/JCLOBe4GPpWaLQTWpuWO9Jy0/icREak+P939dCIwHbgP2ARMT3cyHZb66Ejb5PowM7MSDOZzEp8HLpPUSXH94KZUvwk4NtUvA5YARMTDwBrgEeBHwMUR8Vo6SrgEWEdx99Sa1LavPszMrAQDOgEfERWgkpa3UtyZ1LvNS8CfZra/CriqRv1O4M4a9Zp9mJlZOfyJazMzy3JImJlZlkPCzMyyHBJmZpblkDAzsyyHhJmZZTkkzMwsyyFhZmZZDgkzM8tySJiZWZZDwszMshwSZmaW5ZAwM7Msh4SZmWU5JMzMLMshYWZmWQ4JMzPLckiYmVmWQ8LMzLIcEmZmluWQMDOzLIeEmZllOSTMzCzLIWFmZln9hoSkt0i6T9I/SXpY0pdS/URJ90rqlHSbpMNS/c3peWdaP61qX19I9ccknV5Vb0+1TklLquo1+zAzs3LUcyTxMvDRiDgFeB/QLmk2cA1wXUScBDwLXJDaXwA8m+rXpXZImgHMB94LtAP/Q9Ihkg4BrgfOAGYA56S29NGHmZmVoN+QiEJ3enpoegTwUeD2VF8FnJWW56XnpPVzJCnVV0fEyxHxBNAJnJYenRGxNSJeAVYD89I2uT7MzKwE4+pplP7avx84ieKv/n8G9kbEgdSkC5iclicD2wEi4oCkfcCxqb6xarfV22zvVZ+Vtsn10Xt8i4HFAC0tLVQqlXqm9VtaxsPlMw/033CINTreodDd3d3U/pvBcx4bmjXnZryHwPDNt66QiIjXgPdJmgh8H3j3kI9kECJiObAcoLW1Ndra2hraz9duXcu1W+p6SYbUtnPbSu+zR6VSodHXa7TynMeGZs150ZI7Su8TYGX7hGGZ74DuboqIvcDdwAeBiZJ63lGnADvS8g5gKkBafxSwu7rea5tcfXcffZiZWQnqubvpbekIAknjgY8Dj1KExadSs4XA2rTckZ6T1v8kIiLV56e7n04EpgP3AZuA6elOpsMoLm53pG1yfZiZWQnqObdyHLAqXZd4E7AmIn4o6RFgtaT/AjwA3JTa3wTcIqkT2EPxpk9EPCxpDfAIcAC4OJ3GQtIlwDrgEGBFRDyc9vX5TB9mZlaCfkMiIh4E3l+jvpXizqTe9ZeAP83s6yrgqhr1O4E76+3DzMzK4U9cm5lZlkPCzMyyHBJmZpblkDAzsyyHhJmZZTkkzMwsyyFhZmZZDgkzM8tySJiZWZZDwszMshwSZmaW5ZAwM7Msh4SZmWU5JMzMLMshYWZmWQ4JMzPLckiYmVmWQ8LMzLIcEmZmluWQMDOzLIeEmZllOSTMzCzLIWFmZln9hoSkqZLulvSIpIclXZrqx0haL+nx9PPoVJekZZI6JT0o6dSqfS1M7R+XtLCq/gFJW9I2yySprz7MzKwc9RxJHAAuj4gZwGzgYkkzgCXAhoiYDmxIzwHOAKanx2LgBije8IGlwCzgNGBp1Zv+DcCFVdu1p3quDzMzK0G/IREROyPi/6Tl54BHgcnAPGBVarYKOCstzwNujsJGYKKk44DTgfURsScingXWA+1p3ZERsTEiAri5175q9WFmZiUYN5DGkqYB7wfuBVoiYmda9RTQkpYnA9urNutKtb7qXTXq9NFH73EtpjhqoaWlhUqlMpBp/UbLeLh85oGGth2MRsc7FLq7u5vafzN4zmNDs+bcjPcQGL751h0Skg4Hvgv8h4jYny4bABARISmGfHRV+uojIpYDywFaW1ujra2toT6+dutart0yoNwcEtvObSu9zx6VSoVGX6/RynMeG5o150VL7ii9T4CV7ROGZb513d0k6VCKgLg1Ir6Xyk+nU0Wkn7tSfQcwtWrzKanWV31KjXpffZiZWQnqubtJwE3AoxHx5apVHUDPHUoLgbVV9QXpLqfZwL50ymgdMFfS0emC9VxgXVq3X9Ls1NeCXvuq1YeZmZWgnnMrHwL+HNgi6eep9h+Bq4E1ki4AngTOTuvuBM4EOoEXgPMBImKPpCuBTandFRGxJy1fBKwExgN3pQd99GFmZiXoNyQi4qeAMqvn1GgfwMWZfa0AVtSobwZOrlHfXasPMzMrhz9xbWZmWQ4JMzPLckiYmVmWQ8LMzLIcEmZmluWQMDOzLIeEmZllOSTMzCzLIWFmZlkOCTMzy3JImJlZlkPCzMyyHBJmZpblkDAzsyyHhJmZZTkkzMwsyyFhZmZZDgkzM8tySJiZWZZDwszMshwSZmaW5ZAwM7Msh4SZmWX1GxKSVkjaJemhqtoxktZLejz9PDrVJWmZpE5JD0o6tWqbhan945IWVtU/IGlL2maZJPXVh5mZlaeeI4mVQHuv2hJgQ0RMBzak5wBnANPTYzFwAxRv+MBSYBZwGrC06k3/BuDCqu3a++nDzMxK0m9IRMQ9wJ5e5XnAqrS8Cjirqn5zFDYCEyUdB5wOrI+IPRHxLLAeaE/rjoyIjRERwM299lWrDzMzK8m4BrdriYidafkpoCUtTwa2V7XrSrW+6l016n318VskLaY4cqGlpYVKpTLA6aQOx8PlMw80tO1gNDreodDd3d3U/pvBcx4bmjXnZryHwPDNt9GQ+I2ICEkxFINptI+IWA4sB2htbY22traG+vnarWu5dsugX5IB23ZuW+l99qhUKjT6eo1WnvPY0Kw5L1pyR+l9AqxsnzAs82307qan06ki0s9dqb4DmFrVbkqq9VWfUqPeVx9mZlaSRkOiA+i5Q2khsLaqviDd5TQb2JdOGa0D5ko6Ol2wngusS+v2S5qd7mpa0GtftfowM7OS9HtuRdJ3gDZgkqQuiruUrgbWSLoAeBI4OzW/EzgT6AReAM4HiIg9kq4ENqV2V0REz8XwiyjuoBoP3JUe9NGHmZmVpN+QiIhzMqvm1GgbwMWZ/awAVtSobwZOrlHfXasPMzMrjz9xbWZmWQ4JMzPLckiYmVmWQ8LMzLIcEmZmluWQMDOzLIeEmZllOSTMzCzLIWFmZlkOCTMzy3JImJlZlkPCzMyyHBJmZpblkDAzsyyHhJmZZTkkzMwsyyFhZmZZDgkzM8tySJiZWZZDwszMshwSZmaW5ZAwM7Msh4SZmWU5JMzMLGvEh4SkdkmPSeqUtKTZ4zEzG0tGdEhIOgS4HjgDmAGcI2lGc0dlZjZ2jOiQAE4DOiNia0S8AqwG5jV5TGZmY8a4Zg+gH5OB7VXPu4BZvRtJWgwsTk+7JT3WYH+TgF83uG3DdE3ZPb5BU+bcZJ7z2DCm5vyRawY93xNqFUd6SNQlIpYDywe7H0mbI6J1CIY0anjOY4PnfPAbrvmO9NNNO4CpVc+npJqZmZVgpIfEJmC6pBMlHQbMBzqaPCYzszFjRJ9uiogDki4B1gGHACsi4uFh7HLQp6xGIc95bPCcD37DMl9FxHDs18zMDgIj/XSTmZk1kUPCzMyyxmRI9PdVH5LeLOm2tP5eSdOaMMwhVcecL5P0iKQHJW2QVPOe6dGk3q90kfSvJYWkUX27ZD3zlXR2+j0/LOnbZY9xqNXx7/p4SXdLeiD92z6zGeMcSpJWSNol6aHMeklall6TByWdOqgOI2JMPSgugP8z8LvAYcA/ATN6tbkIuDEtzwdua/a4S5jzR4C3puVPj4U5p3ZHAPcAG4HWZo97mH/H04EHgKPT87c3e9wlzHk58Om0PAPY1uxxD8G8PwycCjyUWX8mcBcgYDZw72D6G4tHEvV81cc8YFVavh2YI0kljnGo9TvniLg7Il5ITzdSfCZlNKv3K12uBK4BXipzcMOgnvleCFwfEc8CRMSuksc41OqZcwBHpuWjgF+VOL5hERH3AHv6aDIPuDkKG4GJko5rtL+xGBK1vupjcq5NRBwA9gHHljK64VHPnKtdQPGXyGjW75zTYfjUiLijzIENk3p+x+8E3inpZ5I2SmovbXTDo545/zVwnqQu4E7gM+UMrakG+t97n0b05ySsfJLOA1qBP2z2WIaTpDcBXwYWNXkoZRpHccqpjeJI8R5JMyNibzMHNczOAVZGxLWSPgjcIunkiHi92QMbLcbikUQ9X/XxmzaSxlEcpu4uZXTDo66vN5H0MeA/AZ+MiJdLGttw6W/ORwAnAxVJ2yjO3XaM4ovX9fyOu4COiHg1Ip4A/i9FaIxW9cz5AmANQET8I/AWii/+O5gN6dcZjcWQqOerPjqAhWn5U8BPIl0RGqX6nbOk9wPfoAiI0X6uGvqZc0Tsi4hJETEtIqZRXIf5ZERsbs5wB62ef9c/oDiKQNIkitNPW0sc41CrZ86/BOYASHoPRUg8U+ooy9cBLEh3Oc0G9kXEzkZ3NuZON0Xmqz4kXQFsjogO4CaKw9JOigtE85s34sGrc85/AxwO/M90jf6XEfHJpg16kOqc80GjzvmuA+ZKegR4DfhcRIzaI+Q653w58E1Jn6W4iL1olP/Bh6TvUIT9pHStZSlwKEBE3Ehx7eVMoBN4ATh/UP2N8tfLzMyG0Vg83WRmZnVySJiZWZZDwszMshwSZmaW5ZAwM7Msh4SZmWU5JMzMLOv/Ab8Iwlf+azqnAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print(df.head()) # Printing the head to see the data columns\n",
        "print('The Total Number of Class: {}'.format(df['Party'].nunique()))\n",
        "print('The Samples Per class:\\n {}'.format(df['Party'].value_counts()))\n",
        "print('The Diagram Shows Below the histogram of class distribution.')\n",
        "df['Party_Numeric_Class'] = df.apply(lambda row : 1 if row['Party'] == 'D' else 0,axis=1)\n",
        "df.hist(column='Party_Numeric_Class')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLdL_CFukNUW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "e1f5e319-6601-4d1f-b627-242266a642c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    0.610875\n",
            "0    0.389125\n",
            "Name: Party_Numeric_Class, dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:ylabel='Party_Numeric_Class'>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(df['Party_Numeric_Class'].value_counts()/df['Party_Numeric_Class'].value_counts().sum())\n",
        "(df['Party_Numeric_Class'].value_counts()/df['Party_Numeric_Class'].value_counts().sum()).plot.pie()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vjV4ilxxv28"
      },
      "source": [
        "### Above we check for class imbalance issue. We conclude that the dataset doesn't have class imbalance issue.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# From Below we take deeper look into the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SEbik5cyImL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ae8432-1891-48c6-80db-d79115b6e31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     On #MemorialDay, we salute all who have bravel...\n",
            "1     On #MemorialDay, we remember the brave men and...\n",
            "2     RT @shmetrolina: We are closed today, May 30th...\n",
            "3     RT @NCDOT: All #NCDMV offices are closed today...\n",
            "4     RT @TSUedu: Never forget <U+0001F499><U+0001F9...\n",
            "5     As Asian American and Pacific Islander Heritag...\n",
            "6     From Team Adams:\\r\\n\\r\\nPlease join us in wish...\n",
            "7     RT @LeaderHoyer: I spoke this week on the trag...\n",
            "8     As we mourn the lives lost in Uvalde, we also ...\n",
            "9     RT @RepDeborahRoss: Thoughts and prayers mea...\n",
            "10    Unfortunately, #NC12 is all too familiar with ...\n",
            "11    May is #MentalHealthAwarenessMonth  and now mo...\n",
            "12    The House has already passed legislation to st...\n",
            "13    I am so sorry to hear of Commissioner Scarboro...\n",
            "14    I am heartbroken by the shooting at Robb Eleme...\n",
            "Name: Tweet, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df['Tweet'].head(15))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTeQuquizDUx"
      },
      "source": [
        "Before we begin with training we would require to do two function:\n",
        "\n",
        "1. Pre-process the data\n",
        "- remove the stop words\n",
        "- remove the punchuations\n",
        "- and remove the numbers\n",
        "\n",
        "---\n",
        "\n",
        "this is deduced from the above output\n",
        "2. We need to sample data into train and validation for the model training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DKLkIuPm4lz"
      },
      "outputs": [],
      "source": [
        "# Gensim Library Performs word2vec transformation and preprocessing of words\n",
        "import gensim #a Python library for topic modeling, document indexing, and similarity retrieval\n",
        "from gensim.models import KeyedVectors #KeyedVectors is a class that allows storing and operating on word vectors (e.g., Word2Vec, GloVe,etc.) in a more memory-efficient way\n",
        "from gensim.parsing.preprocessing import remove_stopwords #examples of stopwords “a,” “the,” “is,” “are,”\n",
        "\n",
        "# Parameters for preprocessing\n",
        "no_tweets = 'All are used'     # no of tweets that will be read from file. All will be used\n",
        "max_tweets_length = 200 # no of words per tweet.\n",
        "max_words = 5000        # this is the size of the index (i.e. most common top words that will be used as features)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def remove_URL(Tweet):\n",
        "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
        "    return url.sub(r\"\", Tweet)\n",
        "\n",
        "\n",
        "def remove_html(Tweet):\n",
        "    html = re.compile(r\"<.*?>\") #HTML tags\n",
        "    return html.sub(r\"\", Tweet)\n",
        "\n",
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"  # Miscellaneous symbols (e.g., dingbats ❒ or ❺)\n",
        "        u\"\\U000024C2-\\U0001F251\"  # Enclosed characters (e.g., circled letters and numbers)\n",
        "        \"]+\",\n",
        "        flags=re.UNICODE,\n",
        "    )\n",
        "    return emoji_pattern.sub(r\"\", string)\n",
        "\n",
        "def clean_tweet(Tweet):\n",
        "  Tweet = re.sub('RT', '', Tweet) #Remove Retweet from txt\n",
        "  Tweet = re.sub('#[A-Za-z0-9]+', '', Tweet) #Remove # from txt\n",
        "  Tweet = re.sub('\\\\n', '', Tweet) #Remove \\n charachter\n",
        "  Tweet = re.sub('@[\\S]*', '', Tweet) #Remove mentions charachter\n",
        "  Tweet = re.sub('^[\\s]+|[\\s]+$', '', Tweet) #Remove leading and trailing whitespaces from txt\n",
        "  return Tweet\n",
        "\n",
        "df[\"Tweet\"] = df.Tweet.map(lambda x: remove_URL(x))\n",
        "df[\"Tweet\"] = df.Tweet.map(lambda x: remove_html(x))\n",
        "df[\"Tweet\"] = df.Tweet.map(lambda x: remove_emoji(x))\n",
        "df[\"Tweet\"] = df.Tweet.map(lambda x: clean_tweet(x))"
      ],
      "metadata": {
        "id": "9ShfEJZdEWBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iqgmoBXVFOZJ",
        "outputId": "1d6aab1c-3f1a-4bd8-bf42-a0de973de577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Party                                              Tweet     Handle  \\\n",
              "0     D  On , we salute all who have bravely served our...  AlmaAdams   \n",
              "1     D  On , we remember the brave men and women who g...  AlmaAdams   \n",
              "2     D  We are closed today, May 30th in observance of...  AlmaAdams   \n",
              "3     D  All  offices are closed today for . \\r\\rOnline...  AlmaAdams   \n",
              "4     D                                       Never forget  AlmaAdams   \n",
              "\n",
              "   Party_Numeric_Class  \n",
              "0                    1  \n",
              "1                    1  \n",
              "2                    1  \n",
              "3                    1  \n",
              "4                    1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67cce5ca-4cb4-494c-8d89-3cff731ccced\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Party</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Handle</th>\n",
              "      <th>Party_Numeric_Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>D</td>\n",
              "      <td>On , we salute all who have bravely served our...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D</td>\n",
              "      <td>On , we remember the brave men and women who g...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D</td>\n",
              "      <td>We are closed today, May 30th in observance of...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D</td>\n",
              "      <td>All  offices are closed today for . \\r\\rOnline...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>D</td>\n",
              "      <td>Never forget</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67cce5ca-4cb4-494c-8d89-3cff731ccced')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67cce5ca-4cb4-494c-8d89-3cff731ccced button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67cce5ca-4cb4-494c-8d89-3cff731ccced');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned_txt']=df['Tweet']"
      ],
      "metadata": {
        "id": "1TEWXbqrMIfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1nvFn0CEQ83"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords_punchuations (row,column_name):\n",
        "    text = remove_stopwords(row[column_name]) # removes stop words\n",
        "    # below function Removes punchuations, numbers, tailing spaces, all the words to lowercase\n",
        "    texts = gensim.utils.simple_preprocess(text) # does some simple tokenisation (splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms)\n",
        "    return texts\n",
        "\n",
        "# axis=1 parameter indicates that the function should be applied row-wise. The processed text (list of tokens) is then assigned back to the 'Tweet' column of the  'df'\n",
        "# below we remove all the unnecessary symbols / special characters from the text\n",
        "column_name = 'Tweet'\n",
        "df['Tweet'] = df.apply(remove_stopwords_punchuations,args=[column_name],axis=1) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rfjp4usqEAoz",
        "outputId": "bb8e6081-eab8-46bf-b388-e9479dee1fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Party                                              Tweet     Handle  \\\n",
              "0      D  [on, salute, bravely, served, country, amp, re...  AlmaAdams   \n",
              "1      D  [on, remember, brave, men, women, gave, lives,...  AlmaAdams   \n",
              "2      D  [we, closed, today, may, th, observance, memor...  AlmaAdams   \n",
              "3      D  [all, offices, closed, today, online, services...  AlmaAdams   \n",
              "4      D                                    [never, forget]  AlmaAdams   \n",
              "..   ...                                                ...        ...   \n",
              "95     D  [campus, community, supporters, congresswoman,...  AlmaAdams   \n",
              "96     D  [thank, hospitality, honoring, fisk, universit...  AlmaAdams   \n",
              "97     D  [congress, complicated, don, school, house, ro...  AlmaAdams   \n",
              "98     D                            [the, debt, damn, high]  AlmaAdams   \n",
              "99     D                  [if, live, davidson, participate]  AlmaAdams   \n",
              "\n",
              "    Party_Numeric_Class                                        cleaned_txt  \n",
              "0                     1  On , we salute all who have bravely served our...  \n",
              "1                     1  On , we remember the brave men and women who g...  \n",
              "2                     1  We are closed today, May 30th in observance of...  \n",
              "3                     1  All  offices are closed today for . \\r\\rOnline...  \n",
              "4                     1                                       Never forget  \n",
              "..                  ...                                                ...  \n",
              "95                    1  Campus Community and Supporters, Congresswoman...  \n",
              "96                    1  Thank you  for your hospitality and for honori...  \n",
              "97                    1  Congress can be complicated and since we dont...  \n",
              "98                    1                         The debt is too damn high.  \n",
              "99                    1       If you live in Davidson, please participate!  \n",
              "\n",
              "[100 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40896b62-d4c0-46fa-80af-390f085f7253\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Party</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Handle</th>\n",
              "      <th>Party_Numeric_Class</th>\n",
              "      <th>cleaned_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>D</td>\n",
              "      <td>[on, salute, bravely, served, country, amp, re...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>On , we salute all who have bravely served our...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D</td>\n",
              "      <td>[on, remember, brave, men, women, gave, lives,...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>On , we remember the brave men and women who g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D</td>\n",
              "      <td>[we, closed, today, may, th, observance, memor...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>We are closed today, May 30th in observance of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D</td>\n",
              "      <td>[all, offices, closed, today, online, services...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>All  offices are closed today for . \\r\\rOnline...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>D</td>\n",
              "      <td>[never, forget]</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>Never forget</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>D</td>\n",
              "      <td>[campus, community, supporters, congresswoman,...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>Campus Community and Supporters, Congresswoman...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>D</td>\n",
              "      <td>[thank, hospitality, honoring, fisk, universit...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>Thank you  for your hospitality and for honori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>D</td>\n",
              "      <td>[congress, complicated, don, school, house, ro...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>Congress can be complicated and since we dont...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>D</td>\n",
              "      <td>[the, debt, damn, high]</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>The debt is too damn high.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>D</td>\n",
              "      <td>[if, live, davidson, participate]</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>If you live in Davidson, please participate!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40896b62-d4c0-46fa-80af-390f085f7253')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40896b62-d4c0-46fa-80af-390f085f7253 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40896b62-d4c0-46fa-80af-390f085f7253');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hF3AILshCemF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fcf5b1d-1704-4d09-948f-f901a9c45c2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Number of Words: 61\n",
            "Average Number of Words accross Reviews: 12.767880218391626\n",
            "Most Common Length of Review: 0    10\n",
            "dtype: int64\n",
            "Total Number of example in our dataset before removing outliers: 1048575\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter #imported to count the occurrances of each unique word in the corpus\n",
        " \n",
        "def get_words_of_Tweets(row,column_name):\n",
        "    max_count = 0 \n",
        "    text = row[column_name]\n",
        "    count = Counter()\n",
        "    for word in text:\n",
        "        count[word] += 1\n",
        "    return len(count)\n",
        "column_name = 'Tweet'\n",
        "df['word_count'] = df.apply(get_words_of_Tweets,args=[column_name],axis=1)\n",
        "\n",
        "print('Max Number of Words: {}'.format(df['word_count'].max()))\n",
        "print('Average Number of Words accross Reviews: {}'.format(df['word_count'].mean()))\n",
        "print('Most Common Length of Review: {}'.format(df['word_count'].mode()))\n",
        "print('Total Number of example in our dataset before removing outliers: {}'.format(len(df)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8brJvTxSGcK5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "cc0508b0-c6b4-4f73-b2d0-fbdea41bacc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Party                                              Tweet     Handle  \\\n",
              "0     D  [on, salute, bravely, served, country, amp, re...  AlmaAdams   \n",
              "1     D  [on, remember, brave, men, women, gave, lives,...  AlmaAdams   \n",
              "2     D  [we, closed, today, may, th, observance, memor...  AlmaAdams   \n",
              "3     D  [all, offices, closed, today, online, services...  AlmaAdams   \n",
              "4     D                                    [never, forget]  AlmaAdams   \n",
              "5     D  [as, asian, american, pacific, islander, herit...  AlmaAdams   \n",
              "6     D  [from, team, adams, please, join, wishing, hap...  AlmaAdams   \n",
              "7     D  [spoke, week, tragic, mass, shooting, robb, el...  AlmaAdams   \n",
              "8     D  [as, mourn, lives, lost, uvalde, remember, hon...  AlmaAdams   \n",
              "9     D  [thoughts, prayers, mean, don, follow, action,...  AlmaAdams   \n",
              "\n",
              "   Party_Numeric_Class                                        cleaned_txt  \\\n",
              "0                    1  On , we salute all who have bravely served our...   \n",
              "1                    1  On , we remember the brave men and women who g...   \n",
              "2                    1  We are closed today, May 30th in observance of...   \n",
              "3                    1  All  offices are closed today for . \\r\\rOnline...   \n",
              "4                    1                                       Never forget   \n",
              "5                    1  As Asian American and Pacific Islander Heritag...   \n",
              "6                    1  From Team Adams:\\r\\rPlease join us in wishing ...   \n",
              "7                    1  I spoke this week on the tragic mass shooting ...   \n",
              "8                    1  As we mourn the lives lost in Uvalde, we also ...   \n",
              "9                    1  Thoughts and prayers mean nothing if we don...   \n",
              "\n",
              "   word_count  \n",
              "0          10  \n",
              "1          19  \n",
              "2          12  \n",
              "3           8  \n",
              "4           2  \n",
              "5          25  \n",
              "6          11  \n",
              "7          13  \n",
              "8          23  \n",
              "9          13  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f39c93c7-dd64-472c-bc17-d5f8c8d2192c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Party</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Handle</th>\n",
              "      <th>Party_Numeric_Class</th>\n",
              "      <th>cleaned_txt</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>D</td>\n",
              "      <td>[on, salute, bravely, served, country, amp, re...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>On , we salute all who have bravely served our...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D</td>\n",
              "      <td>[on, remember, brave, men, women, gave, lives,...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>On , we remember the brave men and women who g...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D</td>\n",
              "      <td>[we, closed, today, may, th, observance, memor...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>We are closed today, May 30th in observance of...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D</td>\n",
              "      <td>[all, offices, closed, today, online, services...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>All  offices are closed today for . \\r\\rOnline...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>D</td>\n",
              "      <td>[never, forget]</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>Never forget</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>D</td>\n",
              "      <td>[as, asian, american, pacific, islander, herit...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>As Asian American and Pacific Islander Heritag...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>D</td>\n",
              "      <td>[from, team, adams, please, join, wishing, hap...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>From Team Adams:\\r\\rPlease join us in wishing ...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>D</td>\n",
              "      <td>[spoke, week, tragic, mass, shooting, robb, el...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>I spoke this week on the tragic mass shooting ...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>D</td>\n",
              "      <td>[as, mourn, lives, lost, uvalde, remember, hon...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>As we mourn the lives lost in Uvalde, we also ...</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>D</td>\n",
              "      <td>[thoughts, prayers, mean, don, follow, action,...</td>\n",
              "      <td>AlmaAdams</td>\n",
              "      <td>1</td>\n",
              "      <td>Thoughts and prayers mean nothing if we don...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f39c93c7-dd64-472c-bc17-d5f8c8d2192c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f39c93c7-dd64-472c-bc17-d5f8c8d2192c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f39c93c7-dd64-472c-bc17-d5f8c8d2192c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df.head(10) # View of pre-processed dataframe 'df'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Training Data"
      ],
      "metadata": {
        "id": "ddciIgjU7BMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and pre-processing constants are listed below\n",
        "\n",
        "embedding_size = 200    # size of embedding. size of 200 is a common choice, as it often provides a good balance between model complexity and representational power\n",
        "validation_split = 0.2 # ratio of data for validation set\n",
        "no_epochs = 50         # No of training cycles for the networks (small number of epochs might result in underfitted model, huge number might lead to overfitting)\n",
        "lr = 0.01 # the learning rate determines how quickly the model's weights are updated during training. A smaller learning rate means slower convergence, but it might lead to a better solution (used to be 0.001) "
      ],
      "metadata": {
        "id": "2x8ZUVx9ZEMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcK9Spo_CemF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc0c38f-2d80-4386-b62f-cac04977ff5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We Calculate the class weights of dataset so that we can train our model well on lower number of classes \n",
            " <class 'dict'>\n",
            "{0: 1.284933349998897, 1: 0.8184983795125423}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import class_weight\n",
        "# Used for class_weights shift in case of class imbalance data.\n",
        "\n",
        "#Spliting the train/test with 80% dataset for training and 20% for testing\n",
        "\n",
        "X = df[\"Tweet\"] # getting reviws from the dataset for training\n",
        "y = df.Party_Numeric_Class # getting ratings of the reviws\n",
        "\n",
        "X_train, x_test, y_train, y_test = train_test_split(\n",
        "     X, y, test_size=validation_split, random_state=42) #used for train test split\n",
        "    #X_train: The input data for the training set\n",
        "    #x_test: The input data for the test set\n",
        "    #y_train: The corresponding labels for the training set\n",
        "    #y_test: The corresponding labels for the test set\n",
        "\n",
        "\n",
        "classes_weights  = class_weight.compute_class_weight(class_weight= 'balanced',classes=np.unique(y),y=y)\n",
        "\n",
        "classes_weights_dict  = dict(enumerate(classes_weights))\n",
        "print('We Calculate the class weights of dataset so that we can train our model well on lower number of classes \\n {}'.format(type(classes_weights_dict)))\n",
        "print(classes_weights_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RBoTt7fCFT3"
      },
      "outputs": [],
      "source": [
        "# Only use tweets that are used for training\n",
        "\n",
        "model = gensim.models.Word2Vec(\n",
        "        X_train,\n",
        "        size = embedding_size, # size of representation  old version of gensim has size = ...\n",
        "        window = 5 ,              # length of frame for neighbours\n",
        "                               # sg = 0 for CBOW, sg = 1 for skipgram.  default is 0\n",
        "                               #iter = 5   no of epochs for w2v. default is 5\n",
        "        min_count= 10 )         # min no of times for word occurs to be included\n",
        "\n",
        "#this code snippet initializes a Word2Vec model using the Gensim library with the specified training data, embedding size, context window size, and minimum word frequency. \n",
        "#The model will learn word embeddings based on the co-occurrence of words in the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzAeBfntIsbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb06147b-382e-4038-bb6c-c6dfdd928a5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tword 0 == amp\n",
            "\tword 1 == the\n",
            "\tword 2 == today\n",
            "\tword 3 == we\n",
            "\tword 4 == it\n",
            "\tword 5 == this\n",
            "\tword 6 == house\n",
            "\tword 7 == act\n",
            "\tword 8 == people\n",
            "\tword 9 == president\n"
          ]
        }
      ],
      "source": [
        "# using trained model to get index of words\n",
        "index_to_key = model.wv.index2word\n",
        "\n",
        "# Visualizing indexed words\n",
        "for index, word in enumerate(index_to_key):\n",
        "    if index == 10:\n",
        "        break\n",
        "    print(f\"\\tword {index} == {word}\")\n",
        "    #In summary, this code snippet extracts the indexed words from a trained Word2Vec model, iterates through the first 10 words in the list, and prints the index and the corresponding word for each. \n",
        "    #This is useful for visualizing the words in the vocabulary and their associated indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0wCLML7m4l5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79221e96-ffd3-4916-f9c1-95b3513a9073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 37, 168, 0, 13, 1490, 22, 1, 158, 2678, 1507, 66, 54, 193, 146, 4, 37, 184, 926, 88, 895, 11, 2996, 1976]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    4   37  168    0   13 1490\n",
            "   22    1  158 2678 1507   66   54  193  146    4   37  184  926   88\n",
            "  895   11 2996 1976]\n"
          ]
        }
      ],
      "source": [
        "# Once we have the index_to_key, we can construct the word_index and also use it to code the sentences.\n",
        "# the coded sentences are then made into a fixed size using pad_sequences\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences #is used for padding and truncating sequences of data. preprocessing techniques applied to sequences of variable length to make them all have the same length\n",
        "\n",
        "word_index = {w: i+1 for i,w in enumerate(index_to_key) if i < max_words-1} # creates a dictionary called word_index that maps each word in the vocabulary (index_to_key) to an integer index max_words(zero is reserved for unknown) \n",
        "\n",
        "\n",
        "sequences_train = [[word_index.get(w, 0) for w in sent] for sent in X_train] # encode the sentences\n",
        "sequences_test = [[word_index.get(w, 0) for w in sent] for sent in x_test] # encode the sentences\n",
        "\n",
        "print(sequences_train[0])\n",
        "# Applying padding to the encodings\n",
        "seqs_truncated_train = pad_sequences(sequences_train, maxlen=max_tweets_length, padding=\"pre\", truncating=\"post\")\n",
        "seqs_truncated_test = pad_sequences(sequences_test, maxlen=max_tweets_length, padding=\"pre\", truncating=\"post\")\n",
        "\n",
        "print(seqs_truncated_train[0])\n",
        "#this code  creates word sequences from the training and testing data, encodes them using a word-to-index dictionary, \n",
        "#and applies padding and truncation to ensure that all sequences have the same length, as required by many machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-rctbR7K0_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2702220-b51f-4baf-87b2-efb677924e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0]\n",
            "[1 0]\n",
            "[[0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "# We apply below process becasuse tensorflow requires the data in categorical format for multiclass classification\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "print(y_train.unique()) \n",
        "print(y_test.unique()) \n",
        "y_train_ca = to_categorical(y_train)\n",
        "y_test_ca = to_categorical(y_test)\n",
        "print(y_train_ca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2vy5YNcQE2O"
      },
      "source": [
        "#Recap\n",
        "### Till now we have successfully \n",
        "1. visualized the data\n",
        "2. Removed stopwords\n",
        "3. Removed spaces\n",
        "4. Removed punchuations\n",
        "5. Removed urls and htmls\n",
        "6. removed emojis\n",
        "7. Removed Numbers\n",
        "8. Removed Special Characters\n",
        "9. Converted all the text to lowercase\n",
        "10. Weight dictionary for class balancing\n",
        "11. Train val Split of the dataset \n",
        "12. Converted the classes to categorical formation\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Now we step towards training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfOO8sHBrIIK"
      },
      "source": [
        "# Training With Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFrNK6NbGCkz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "  \n",
        "  vocab_size = len(word_index) + 1  \n",
        "  \n",
        "  embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "  with open(filepath) as f:\n",
        "    for line in f:\n",
        "      word, *vector = line.split()\n",
        "      if word in word_index:\n",
        "        idx = word_index.get(word)\n",
        "        vector = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
        "        embedding_matrix[idx,:] = vector\n",
        "  return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQKjvUMyETSb"
      },
      "outputs": [],
      "source": [
        "# Loading pre-trained embeddings from the glove file\n",
        "path_to_glove_file = \"drive/MyDrive/glove.6B.200d.txt\"\n",
        "# Getting the embeddings matrix for our words in the word_index\n",
        "embedding_matrix = create_embedding_matrix(path_to_glove_file,\n",
        "                                            word_index,\n",
        "                                            embedding_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGUPYf8q3PW8"
      },
      "outputs": [],
      "source": [
        "# fix random seed for reproducibility\n",
        "np.random.seed(66542)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint # Saving Model on Certain Criteria of improving\n",
        "from tensorflow.keras.optimizers import Adam # The model optimizer  popular and effective optimization algorithm for training deep learning models\n",
        "save_path = 'drive/MyDrive/ceoNN/models/' \n",
        "model_save_name = 'saved_training_with_Glove' + \".h5\"\n",
        "checkpoint_glove = ModelCheckpoint(save_path + model_save_name, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "def scheduler(epoch, lr):\n",
        "   if epoch < 10:\n",
        "     return lr\n",
        "   elif epoch > 30:\n",
        "     return lr\n",
        "   elif (epoch % 10 == 0):\n",
        "     return lr * tf.math.exp(-0.1)\n",
        "   else:\n",
        "     return lr\n",
        "    \n",
        "\n",
        "learning_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler) # applying adaptive learning rate to the model.\n",
        "\n",
        "adam = Adam(learning_rate=lr) # To change the learning rate\n",
        "\n",
        "callbacks = [checkpoint_glove,learning_schedule]\n",
        "#this code sets up the necessary configurations for training a neural network using TensorFlow and Keras, \n",
        "#including saving the best model, applying a custom learning rate schedule, and using the Adam optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_EloVYq3vAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec15abd4-a1d1-4ead-e22c-9db4a12f910c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 200)          1000000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 198, 150)          90150     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 150)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 60)                9060      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 60)                0         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 60)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 122       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,099,332\n",
            "Trainable params: 1,099,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "import keras\n",
        "from tensorflow.keras.layers import Conv1D,GlobalMaxPooling1D,Dense,Dropout,Activation,Embedding\n",
        "vocab_size = len(word_index) + 1\n",
        "#defines a Keras Sequential model for a text classification task. \n",
        "#The model consists of an embedding layer followed by a 1D convolutional layer, a global max pooling layer, two dense layers, and dropout and activation layers. \n",
        "#Let's break down each layer\n",
        "model_c = Sequential()\n",
        "# Embedding Matrix initialize the weights on the input layer\n",
        "model_c.add(Embedding(vocab_size, embedding_size, embeddings_initializer=keras.initializers.Constant(embedding_matrix), input_length=embedding_size))\n",
        "model_c.add(Conv1D(150,3,padding = 'valid' , activation = 'relu',strides = 1 , input_shape = (max_words,embedding_size))) \n",
        "model_c.add(GlobalMaxPooling1D())\n",
        "model_c.add(Dense(60)) # (Dense layer can be increased or decreased)\n",
        "model_c.add(Dropout(0.8)) # Dropout rate added to avoid overfitting (Can be experimented)\n",
        "model_c.add(Activation('relu'))\n",
        "model_c.add(Dense(2)) # Dense Two is equal to number of classes\n",
        "model_c.add(Activation('softmax'))\n",
        "\n",
        "model_c.compile(loss = 'binary_crossentropy',optimizer = adam , metrics = ['accuracy'])\n",
        "print(model_c.summary())\n",
        "#Layers: The model has 9 layers (1 Embedding, 1 Conv1D, 1 GlobalMaxPooling1D, 2 Dense, 1 Dropout, and 3 Activation layers).\n",
        "#Outputs: The model outputs a probability distribution over two classes, which is represented as a dense vector of size 2."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#start Model Traning by using model.fit\n",
        "history_c = model_c.fit(seqs_truncated_train, y_train_ca,\n",
        "                        batch_size = 512,epochs = 30,\n",
        "                        validation_data = (seqs_truncated_test,y_test_ca),\n",
        "                        callbacks=[checkpoint_glove],class_weight=classes_weights_dict)"
      ],
      "metadata": {
        "id": "_bs2migM0NER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99e071c3-9801-4d1a-c2c0-8860858da6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.5419 - accuracy: 0.7243\n",
            "Epoch 1: val_accuracy improved from -inf to 0.74765, saving model to drive/MyDrive/ceoNN/models/saved_training_with_Glove.h5\n",
            "1639/1639 [==============================] - 83s 51ms/step - loss: 0.5419 - accuracy: 0.7243 - val_loss: 0.4947 - val_accuracy: 0.7476\n",
            "Epoch 2/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.4993 - accuracy: 0.7526\n",
            "Epoch 2: val_accuracy improved from 0.74765 to 0.75488, saving model to drive/MyDrive/ceoNN/models/saved_training_with_Glove.h5\n",
            "1639/1639 [==============================] - 70s 42ms/step - loss: 0.4993 - accuracy: 0.7526 - val_loss: 0.4833 - val_accuracy: 0.7549\n",
            "Epoch 3/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.4725 - accuracy: 0.7703\n",
            "Epoch 3: val_accuracy improved from 0.75488 to 0.76325, saving model to drive/MyDrive/ceoNN/models/saved_training_with_Glove.h5\n",
            "1639/1639 [==============================] - 69s 42ms/step - loss: 0.4725 - accuracy: 0.7703 - val_loss: 0.4705 - val_accuracy: 0.7633\n",
            "Epoch 4/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.7864\n",
            "Epoch 4: val_accuracy improved from 0.76325 to 0.76339, saving model to drive/MyDrive/ceoNN/models/saved_training_with_Glove.h5\n",
            "1639/1639 [==============================] - 68s 41ms/step - loss: 0.4456 - accuracy: 0.7864 - val_loss: 0.4682 - val_accuracy: 0.7634\n",
            "Epoch 5/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.4187 - accuracy: 0.8004\n",
            "Epoch 5: val_accuracy improved from 0.76339 to 0.76647, saving model to drive/MyDrive/ceoNN/models/saved_training_with_Glove.h5\n",
            "1639/1639 [==============================] - 67s 41ms/step - loss: 0.4187 - accuracy: 0.8004 - val_loss: 0.4735 - val_accuracy: 0.7665\n",
            "Epoch 6/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.3941 - accuracy: 0.8141\n",
            "Epoch 6: val_accuracy improved from 0.76647 to 0.76683, saving model to drive/MyDrive/ceoNN/models/saved_training_with_Glove.h5\n",
            "1639/1639 [==============================] - 67s 41ms/step - loss: 0.3941 - accuracy: 0.8141 - val_loss: 0.4857 - val_accuracy: 0.7668\n",
            "Epoch 7/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.3712 - accuracy: 0.8248\n",
            "Epoch 7: val_accuracy improved from 0.76683 to 0.76871, saving model to drive/MyDrive/ceoNN/models/saved_training_with_Glove.h5\n",
            "1639/1639 [==============================] - 68s 42ms/step - loss: 0.3712 - accuracy: 0.8248 - val_loss: 0.5014 - val_accuracy: 0.7687\n",
            "Epoch 8/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.3491 - accuracy: 0.8358\n",
            "Epoch 8: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 65s 39ms/step - loss: 0.3491 - accuracy: 0.8358 - val_loss: 0.5373 - val_accuracy: 0.7599\n",
            "Epoch 9/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.3295 - accuracy: 0.8444\n",
            "Epoch 9: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 65s 40ms/step - loss: 0.3295 - accuracy: 0.8444 - val_loss: 0.5471 - val_accuracy: 0.7678\n",
            "Epoch 10/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.3115 - accuracy: 0.8528\n",
            "Epoch 10: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 64s 39ms/step - loss: 0.3115 - accuracy: 0.8528 - val_loss: 0.6087 - val_accuracy: 0.7671\n",
            "Epoch 11/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.2940 - accuracy: 0.8604\n",
            "Epoch 11: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 65s 39ms/step - loss: 0.2940 - accuracy: 0.8604 - val_loss: 0.6607 - val_accuracy: 0.7605\n",
            "Epoch 12/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.2793 - accuracy: 0.8434\n",
            "Epoch 12: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 64s 39ms/step - loss: 0.2793 - accuracy: 0.8434 - val_loss: 0.6885 - val_accuracy: 0.7516\n",
            "Epoch 13/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.2656 - accuracy: 0.8397\n",
            "Epoch 13: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 64s 39ms/step - loss: 0.2656 - accuracy: 0.8397 - val_loss: 0.7399 - val_accuracy: 0.7536\n",
            "Epoch 14/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.2537 - accuracy: 0.8469\n",
            "Epoch 14: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 65s 40ms/step - loss: 0.2537 - accuracy: 0.8469 - val_loss: 0.7421 - val_accuracy: 0.7454\n",
            "Epoch 15/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.2429 - accuracy: 0.8533\n",
            "Epoch 15: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 65s 39ms/step - loss: 0.2429 - accuracy: 0.8533 - val_loss: 0.8440 - val_accuracy: 0.7482\n",
            "Epoch 16/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.8572\n",
            "Epoch 16: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 65s 40ms/step - loss: 0.2336 - accuracy: 0.8572 - val_loss: 0.8868 - val_accuracy: 0.7502\n",
            "Epoch 17/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.8619\n",
            "Epoch 17: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 63s 39ms/step - loss: 0.2246 - accuracy: 0.8619 - val_loss: 0.9601 - val_accuracy: 0.7496\n",
            "Epoch 18/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.2162 - accuracy: 0.8671\n",
            "Epoch 18: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 63s 39ms/step - loss: 0.2162 - accuracy: 0.8671 - val_loss: 0.9937 - val_accuracy: 0.7460\n",
            "Epoch 19/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.2095 - accuracy: 0.8707\n",
            "Epoch 19: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 64s 39ms/step - loss: 0.2095 - accuracy: 0.8707 - val_loss: 0.9930 - val_accuracy: 0.7502\n",
            "Epoch 20/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.2028 - accuracy: 0.8752\n",
            "Epoch 20: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 64s 39ms/step - loss: 0.2028 - accuracy: 0.8752 - val_loss: 1.0692 - val_accuracy: 0.7459\n",
            "Epoch 21/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.1969 - accuracy: 0.8792\n",
            "Epoch 21: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 64s 39ms/step - loss: 0.1969 - accuracy: 0.8792 - val_loss: 1.0605 - val_accuracy: 0.7465\n",
            "Epoch 22/30\n",
            "1638/1639 [============================>.] - ETA: 0s - loss: 0.1914 - accuracy: 0.8832\n",
            "Epoch 22: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 64s 39ms/step - loss: 0.1914 - accuracy: 0.8832 - val_loss: 1.1042 - val_accuracy: 0.7519\n",
            "Epoch 23/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.1851 - accuracy: 0.8869\n",
            "Epoch 23: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 65s 39ms/step - loss: 0.1851 - accuracy: 0.8869 - val_loss: 1.1722 - val_accuracy: 0.7499\n",
            "Epoch 24/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.1787 - accuracy: 0.8908\n",
            "Epoch 24: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 64s 39ms/step - loss: 0.1787 - accuracy: 0.8908 - val_loss: 1.2164 - val_accuracy: 0.7474\n",
            "Epoch 25/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.1743 - accuracy: 0.8938\n",
            "Epoch 25: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 64s 39ms/step - loss: 0.1743 - accuracy: 0.8938 - val_loss: 1.2448 - val_accuracy: 0.7561\n",
            "Epoch 26/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.8968\n",
            "Epoch 26: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 65s 39ms/step - loss: 0.1694 - accuracy: 0.8968 - val_loss: 1.2328 - val_accuracy: 0.7452\n",
            "Epoch 27/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.8994\n",
            "Epoch 27: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 64s 39ms/step - loss: 0.1655 - accuracy: 0.8994 - val_loss: 1.3711 - val_accuracy: 0.7547\n",
            "Epoch 28/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.9026\n",
            "Epoch 28: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 64s 39ms/step - loss: 0.1610 - accuracy: 0.9026 - val_loss: 1.3951 - val_accuracy: 0.7560\n",
            "Epoch 29/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9056\n",
            "Epoch 29: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 64s 39ms/step - loss: 0.1569 - accuracy: 0.9056 - val_loss: 1.4015 - val_accuracy: 0.7508\n",
            "Epoch 30/30\n",
            "1639/1639 [==============================] - ETA: 0s - loss: 0.1534 - accuracy: 0.9077\n",
            "Epoch 30: val_accuracy did not improve from 0.76871\n",
            "1639/1639 [==============================] - 65s 39ms/step - loss: 0.1534 - accuracy: 0.9077 - val_loss: 1.3761 - val_accuracy: 0.7493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training Accuracy : {}'.format(history_c.history['accuracy'][-1]))\n",
        "print('Validation Accuracy : {}'.format(history_c.history['val_accuracy'][-1]))\n",
        "\n",
        "scores = model_c.evaluate(seqs_truncated_test, y_test_ca, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "metadata": {
        "id": "oiJWqB__gQNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0122a1a5-a4cb-4246-ba98-2b0ddae2aa85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy : 0.9077045321464539\n",
            "Validation Accuracy : 0.749316930770874\n",
            "6554/6554 [==============================] - 26s 4ms/step - loss: 1.3761 - accuracy: 0.7493\n",
            "Accuracy: 74.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_MSADyld_BV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc675036-3052-42ac-ceac-60b53d049228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6554/6554 [==============================] - 40s 6ms/step\n",
            "[1 0 0 ... 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "# Results withut glove using word to vec\n",
        "results_with_glove = model_c.predict(seqs_truncated_test) # Finding Predicted Score over validatoin data\n",
        "results_class_wg = np.array(np.argmax(results_with_glove,axis=1),dtype=int) # Finding the class of each review in validation\n",
        "print(results_class_wg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3jO3yw3eRzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0619d9ce-33b9-4efc-f551-bd5a99f50dab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results with Glove\n",
            "F1 Score: 0.7521762774016449 \n",
            "Recall Score: 0.7493169301194478\n",
            "Precision Score: 0.7633617820068971\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print('Results with Glove')\n",
        "# average is using with argumented weighted in case of multiclass classification\n",
        "res_f1 = f1_score(y_test,results_class_wg,average='weighted')\n",
        "print('F1 Score: {} '.format(res_f1))\n",
        "res_rc = recall_score(y_test,results_class_wg,average='weighted')\n",
        "print('Recall Score: {}'.format(res_rc))\n",
        "res_prec = precision_score(y_test,results_class_wg,average='weighted')\n",
        "print('Precision Score: {}'.format(res_prec))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We create Confusion matrix now"
      ],
      "metadata": {
        "id": "l8eP0nVXevPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    y_true_for_class = np.array(y_true,dtype=int)\n",
        "    y_pred_for_class = np.array(y_pred,dtype=int)\n",
        "    #classes = classes[unique_labels(y_true_for_class, y_pred_for_class)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10,10))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    #fig.()\n",
        "    plt.savefig(file_path+ title+'.png')\n",
        "    return ax"
      ],
      "metadata": {
        "id": "1PZBaYecayCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'drive/MyDrive/ceoNN/results/'\n",
        "class_labels = ['R' , 'D']\n",
        "plot_confusion_matrix(y_test.astype(str),\n",
        "                      results_class_wg.astype(str),classes=class_labels,\n",
        "                      title='Confusion Matrix With Glove')"
      ],
      "metadata": {
        "id": "iV7OzATrbl8O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "outputId": "9b7fb09a-1048-47e5-cf75-c1c657b073f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[62929 18447]\n",
            " [34125 94214]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:title={'center':'Confusion Matrix With Glove'}, xlabel='Predicted label', ylabel='True label'>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing On CEO DATASET"
      ],
      "metadata": {
        "id": "cT5LSk8ozVjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if the model is already trained we can use below function to load the weights from saved model file. \n",
        "model_c.load_weights('drive/MyDrive/ceoNN/models/saved_training_with_Glove.h5')"
      ],
      "metadata": {
        "id": "7vBy0Gh6jvhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CEO Data for the predictions\n",
        "df_ceo = pd.read_csv('/content/drive/MyDrive/ceo.csv')\n",
        "print(df_ceo.head(15))"
      ],
      "metadata": {
        "id": "OLv84ozmvSZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6755fb5c-89a4-45ed-8139-fe179aea9306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     username                   id                 date  \\\n",
            "0   @tim_cook  1200060640469159939  2019-11-28 14:35:27   \n",
            "1   @tim_cook  1200047686180835328  2019-11-28 13:43:58   \n",
            "2   @tim_cook  1199872990718169089  2019-11-28 02:09:48   \n",
            "3   @tim_cook  1199855397617704970  2019-11-28 00:59:53   \n",
            "4   @tim_cook  1199767313890922497  2019-11-27 19:09:52   \n",
            "5   @tim_cook  1197141315064086530  2019-11-20 13:15:05   \n",
            "6   @tim_cook  1196927442906013696  2019-11-19 23:05:14   \n",
            "7   @tim_cook  1196914279967903744  2019-11-19 22:12:56   \n",
            "8   @tim_cook  1195833226972913664  2019-11-16 22:37:13   \n",
            "9   @tim_cook  1195399185815572480  2019-11-15 17:52:29   \n",
            "10  @tim_cook  1195073339393314818  2019-11-14 20:17:42   \n",
            "11  @tim_cook  1194985641148182528  2019-11-14 14:29:13   \n",
            "12  @tim_cook  1194614812195442688  2019-11-13 13:55:40   \n",
            "13  @tim_cook  1194607635590332416  2019-11-13 13:27:09   \n",
            "14  @tim_cook  1193879150357925889  2019-11-11 13:12:25   \n",
            "\n",
            "                                                tweet  retweets  likes  \n",
            "0   On this #Thanksgiving, I am reflecting on the ...       546   4434  \n",
            "1   Wishing everyone a #HappyThanksgiving filled w...       575   6097  \n",
            "2   Tomorrow the incredible @MNightShyamalan’s ser...       412   2607  \n",
            "3   Thanksgiving Day challenge! Close your rings w...       394   3932  \n",
            "4   As many of you travel to be with loved ones to...      1310   8436  \n",
            "5   The construction of our new Austin campus is u...      3804  23155  \n",
            "6   It’s incredible to see how Salesforce and thei...       611   4750  \n",
            "7   Love this look at Chicago through the eyes of ...       200   2185  \n",
            "8   We’re proud to team up with @TSUedu and @nc100...       219   1866  \n",
            "9   “The innovation of Night mode is incredible! I...       757   6827  \n",
            "10  Our hearts are broken for the students, parent...       605   6004  \n",
            "11  The Research app is a game changer. Participan...       775   4626  \n",
            "12  We’re inspired by the things pro customers cre...      2685  14180  \n",
            "13  Pros — you asked for it. And it’s here. https:...      4174  21409  \n",
            "14  \"Never was so much owed by so many to so few.\"...       644   6096  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-processing the text\n",
        "column_name = 'tweet'\n",
        "df_ceo['pre_processed_tweet'] = df_ceo.apply(remove_stopwords_punchuations,args=[column_name],axis=1) "
      ],
      "metadata": {
        "id": "LtiNxmyJvic1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ceo.head(15)"
      ],
      "metadata": {
        "id": "GP8Ubp7ExeoR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "ab769e13-efc9-4359-9ca1-7cc9fb05b4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     username                   id                 date  \\\n",
              "0   @tim_cook  1200060640469159939  2019-11-28 14:35:27   \n",
              "1   @tim_cook  1200047686180835328  2019-11-28 13:43:58   \n",
              "2   @tim_cook  1199872990718169089  2019-11-28 02:09:48   \n",
              "3   @tim_cook  1199855397617704970  2019-11-28 00:59:53   \n",
              "4   @tim_cook  1199767313890922497  2019-11-27 19:09:52   \n",
              "5   @tim_cook  1197141315064086530  2019-11-20 13:15:05   \n",
              "6   @tim_cook  1196927442906013696  2019-11-19 23:05:14   \n",
              "7   @tim_cook  1196914279967903744  2019-11-19 22:12:56   \n",
              "8   @tim_cook  1195833226972913664  2019-11-16 22:37:13   \n",
              "9   @tim_cook  1195399185815572480  2019-11-15 17:52:29   \n",
              "10  @tim_cook  1195073339393314818  2019-11-14 20:17:42   \n",
              "11  @tim_cook  1194985641148182528  2019-11-14 14:29:13   \n",
              "12  @tim_cook  1194614812195442688  2019-11-13 13:55:40   \n",
              "13  @tim_cook  1194607635590332416  2019-11-13 13:27:09   \n",
              "14  @tim_cook  1193879150357925889  2019-11-11 13:12:25   \n",
              "\n",
              "                                                tweet  retweets  likes  \\\n",
              "0   On this #Thanksgiving, I am reflecting on the ...       546   4434   \n",
              "1   Wishing everyone a #HappyThanksgiving filled w...       575   6097   \n",
              "2   Tomorrow the incredible @MNightShyamalan’s ser...       412   2607   \n",
              "3   Thanksgiving Day challenge! Close your rings w...       394   3932   \n",
              "4   As many of you travel to be with loved ones to...      1310   8436   \n",
              "5   The construction of our new Austin campus is u...      3804  23155   \n",
              "6   It’s incredible to see how Salesforce and thei...       611   4750   \n",
              "7   Love this look at Chicago through the eyes of ...       200   2185   \n",
              "8   We’re proud to team up with @TSUedu and @nc100...       219   1866   \n",
              "9   “The innovation of Night mode is incredible! I...       757   6827   \n",
              "10  Our hearts are broken for the students, parent...       605   6004   \n",
              "11  The Research app is a game changer. Participan...       775   4626   \n",
              "12  We’re inspired by the things pro customers cre...      2685  14180   \n",
              "13  Pros — you asked for it. And it’s here. https:...      4174  21409   \n",
              "14  \"Never was so much owed by so many to so few.\"...       644   6096   \n",
              "\n",
              "                                  pre_processed_tweet  \n",
              "0   [on, thanksgiving, reflecting, dreamers, as, e...  \n",
              "1   [wishing, filled, joy, amp, happiness, reflect...  \n",
              "2   [tomorrow, incredible, mnightshyamalan, series...  \n",
              "3   [thanksgiving, day, challenge, close, rings, f...  \n",
              "4   [as, travel, loved, ones, today, remember, pre...  \n",
              "5   [the, construction, new, austin, campus, under...  \n",
              "6   [it, incredible, salesforce, passionate, devel...  \n",
              "7   [love, look, chicago, eyes, students, drw, col...  \n",
              "8   [we, re, proud, team, tsuedu, nc, bwinc, girls...  \n",
              "9   [the, innovation, night, mode, incredible, it,...  \n",
              "10  [our, hearts, broken, students, parents, teach...  \n",
              "11  [the, research, app, game, changer, participan...  \n",
              "12  [we, re, inspired, things, pro, customers, cre...  \n",
              "13  [pros, asked, it, and, it, here, https, co, rs...  \n",
              "14  [never, owed, few, winston, churchill, to, vet...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8178bb18-086c-405b-857f-4754b9c03507\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>tweet</th>\n",
              "      <th>retweets</th>\n",
              "      <th>likes</th>\n",
              "      <th>pre_processed_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1200060640469159939</td>\n",
              "      <td>2019-11-28 14:35:27</td>\n",
              "      <td>On this #Thanksgiving, I am reflecting on the ...</td>\n",
              "      <td>546</td>\n",
              "      <td>4434</td>\n",
              "      <td>[on, thanksgiving, reflecting, dreamers, as, e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1200047686180835328</td>\n",
              "      <td>2019-11-28 13:43:58</td>\n",
              "      <td>Wishing everyone a #HappyThanksgiving filled w...</td>\n",
              "      <td>575</td>\n",
              "      <td>6097</td>\n",
              "      <td>[wishing, filled, joy, amp, happiness, reflect...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1199872990718169089</td>\n",
              "      <td>2019-11-28 02:09:48</td>\n",
              "      <td>Tomorrow the incredible @MNightShyamalan’s ser...</td>\n",
              "      <td>412</td>\n",
              "      <td>2607</td>\n",
              "      <td>[tomorrow, incredible, mnightshyamalan, series...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1199855397617704970</td>\n",
              "      <td>2019-11-28 00:59:53</td>\n",
              "      <td>Thanksgiving Day challenge! Close your rings w...</td>\n",
              "      <td>394</td>\n",
              "      <td>3932</td>\n",
              "      <td>[thanksgiving, day, challenge, close, rings, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1199767313890922497</td>\n",
              "      <td>2019-11-27 19:09:52</td>\n",
              "      <td>As many of you travel to be with loved ones to...</td>\n",
              "      <td>1310</td>\n",
              "      <td>8436</td>\n",
              "      <td>[as, travel, loved, ones, today, remember, pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1197141315064086530</td>\n",
              "      <td>2019-11-20 13:15:05</td>\n",
              "      <td>The construction of our new Austin campus is u...</td>\n",
              "      <td>3804</td>\n",
              "      <td>23155</td>\n",
              "      <td>[the, construction, new, austin, campus, under...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1196927442906013696</td>\n",
              "      <td>2019-11-19 23:05:14</td>\n",
              "      <td>It’s incredible to see how Salesforce and thei...</td>\n",
              "      <td>611</td>\n",
              "      <td>4750</td>\n",
              "      <td>[it, incredible, salesforce, passionate, devel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1196914279967903744</td>\n",
              "      <td>2019-11-19 22:12:56</td>\n",
              "      <td>Love this look at Chicago through the eyes of ...</td>\n",
              "      <td>200</td>\n",
              "      <td>2185</td>\n",
              "      <td>[love, look, chicago, eyes, students, drw, col...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1195833226972913664</td>\n",
              "      <td>2019-11-16 22:37:13</td>\n",
              "      <td>We’re proud to team up with @TSUedu and @nc100...</td>\n",
              "      <td>219</td>\n",
              "      <td>1866</td>\n",
              "      <td>[we, re, proud, team, tsuedu, nc, bwinc, girls...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1195399185815572480</td>\n",
              "      <td>2019-11-15 17:52:29</td>\n",
              "      <td>“The innovation of Night mode is incredible! I...</td>\n",
              "      <td>757</td>\n",
              "      <td>6827</td>\n",
              "      <td>[the, innovation, night, mode, incredible, it,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1195073339393314818</td>\n",
              "      <td>2019-11-14 20:17:42</td>\n",
              "      <td>Our hearts are broken for the students, parent...</td>\n",
              "      <td>605</td>\n",
              "      <td>6004</td>\n",
              "      <td>[our, hearts, broken, students, parents, teach...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1194985641148182528</td>\n",
              "      <td>2019-11-14 14:29:13</td>\n",
              "      <td>The Research app is a game changer. Participan...</td>\n",
              "      <td>775</td>\n",
              "      <td>4626</td>\n",
              "      <td>[the, research, app, game, changer, participan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1194614812195442688</td>\n",
              "      <td>2019-11-13 13:55:40</td>\n",
              "      <td>We’re inspired by the things pro customers cre...</td>\n",
              "      <td>2685</td>\n",
              "      <td>14180</td>\n",
              "      <td>[we, re, inspired, things, pro, customers, cre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1194607635590332416</td>\n",
              "      <td>2019-11-13 13:27:09</td>\n",
              "      <td>Pros — you asked for it. And it’s here. https:...</td>\n",
              "      <td>4174</td>\n",
              "      <td>21409</td>\n",
              "      <td>[pros, asked, it, and, it, here, https, co, rs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1193879150357925889</td>\n",
              "      <td>2019-11-11 13:12:25</td>\n",
              "      <td>\"Never was so much owed by so many to so few.\"...</td>\n",
              "      <td>644</td>\n",
              "      <td>6096</td>\n",
              "      <td>[never, owed, few, winston, churchill, to, vet...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8178bb18-086c-405b-857f-4754b9c03507')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8178bb18-086c-405b-857f-4754b9c03507 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8178bb18-086c-405b-857f-4754b9c03507');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing test CEO data to be feed into the model.\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "sequences_test_ceo = [[word_index.get(w, 0) for w in sent] for sent in df_ceo['pre_processed_tweet']] # Encode the sentences ceo dataset\n",
        "\n",
        "#Checking the encoding by printing it.\n",
        "print('Before padding encodings')\n",
        "print(sequences_test_ceo[0])\n",
        "\n",
        "print('After padding encodings')\n",
        "seqs_truncated_ceo = pad_sequences(sequences_test_ceo, maxlen=max_tweets_length, padding=\"pre\", truncating=\"post\")\n",
        "print(seqs_truncated_train[0]) "
      ],
      "metadata": {
        "id": "9GGJAKT6xjja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e0c5642-dbbc-48b4-df9c-d628d59fd9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before padding encodings\n",
            "[85, 1735, 0, 1468, 54, 1199, 23, 300, 63, 1185, 1769, 372, 249, 0, 0]\n",
            "After padding encodings\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    4   37  168    0   13 1490\n",
            "   22    1  158 2678 1507   66   54  193  146    4   37  184  926   88\n",
            "  895   11 2996 1976]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making Prediction on the test data CEO\n",
        "test_ceo_results = model_c.predict(seqs_truncated_ceo)\n",
        "print('Prediction On the CEO Dataset')\n",
        "print(test_ceo_results[0:10,:])"
      ],
      "metadata": {
        "id": "ym3TwOnwykAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "314a7b61-c730-4708-f2bc-b4c709eccf87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1823/1823 [==============================] - 4s 2ms/step\n",
            "Prediction On the CEO Dataset\n",
            "[[2.7672490e-06 9.9999726e-01]\n",
            " [3.8216636e-01 6.1783367e-01]\n",
            " [9.9997330e-01 2.6653684e-05]\n",
            " [5.5915332e-01 4.4084668e-01]\n",
            " [9.6569055e-01 3.4309506e-02]\n",
            " [1.6408367e-03 9.9835914e-01]\n",
            " [4.6936738e-01 5.3063256e-01]\n",
            " [2.1285759e-03 9.9787140e-01]\n",
            " [7.0226152e-04 9.9929774e-01]\n",
            " [4.8708910e-01 5.1291090e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Class predict on argmax, having maxium probability of two classes\n",
        "classes_predicted_on_ceo = np.argmax(test_ceo_results,axis=1)\n",
        "print('Predicted Classes')\n",
        "print(classes_predicted_on_ceo[:10])"
      ],
      "metadata": {
        "id": "esoLgqlNzMMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d979fc77-4281-49f7-8639-45d5566b5c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Classes\n",
            "[1 1 0 0 0 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_ceo['Class Probabilites'] = list(test_ceo_results)\n",
        "df_ceo['Predicted Classes'] = list(classes_predicted_on_ceo)"
      ],
      "metadata": {
        "id": "-n7XpPU6zwhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text 2 Emotion Part Starts From Below"
      ],
      "metadata": {
        "id": "u7pl8otz31Dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For Text to Emotion Library Installation Phase on Colab\n",
        "!pip install text2emotion"
      ],
      "metadata": {
        "id": "T6YDOZAF3neq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07fc102d-d203-4a30-b591-84aa564819ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting text2emotion\n",
            "  Downloading text2emotion-0.0.5-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from text2emotion) (3.7)\n",
            "Collecting emoji>=0.6.0\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk->text2emotion) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->text2emotion) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->text2emotion) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->text2emotion) (2022.6.2)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=6ccd06d12733b25ea85c20930bdc624a1f63da20a29862a5606f409e4edcda92\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/62/9e/a6b27a681abcde69970dbc0326ff51955f3beac72f15696984\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, text2emotion\n",
            "Successfully installed emoji-2.2.0 text2emotion-0.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_ceo = df_ceo.head(100)"
      ],
      "metadata": {
        "id": "b3XnexML3lGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import text2emotion as te\n",
        "from tqdm import tqdm\n",
        "\n",
        "tqdm.pandas()\n",
        "list_of_columns = ['Happy','Angry','Surprise', 'Sad', 'Fear']\n",
        "# Taking alot of time processing each tweet.\n",
        "list_of_emotion_scores = []\n",
        "def get_emotions_of_tweet(row,column_name):\n",
        "  tweet = row[column_name]\n",
        "  emotions_probability =  te.get_emotion(str(tweet))\n",
        "  \n",
        "  #emotion_predicted = max(emotions_probability, key=emotions_probability.get)\n",
        "  \n",
        "  list_of_emotion_scores.append([emotions_probability['Happy'] , emotions_probability['Angry'] ,emotions_probability['Surprise'],emotions_probability['Sad'] , emotions_probability['Fear']])\n",
        "  \n",
        "  \n",
        "\n",
        "column_name ='tweet'\n",
        "df_ceo.progress_apply(get_emotions_of_tweet,args=[column_name],axis=1)\n"
      ],
      "metadata": {
        "id": "5nIg1-ud36ZY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "8be62573-a9f1-477a-f82f-45701c6f1ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/58313 [00:00<33:25, 29.08it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-bb2e8e0ec644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mcolumn_name\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdf_ceo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_emotions_of_tweet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8739\u001b[0m         )\n\u001b[0;32m-> 8740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-bb2e8e0ec644>\u001b[0m in \u001b[0;36mget_emotions_of_tweet\u001b[0;34m(row, column_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_emotions_of_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0memotions_probability\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m#emotion_predicted = max(emotions_probability, key=emotions_probability.get)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/text2emotion/__init__.py\u001b[0m in \u001b[0;36mget_emotion\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m   2714\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2716\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2717\u001b[0m     \u001b[0memotion_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2718\u001b[0m     \u001b[0memotions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"Happy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Angry\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Surprise\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sad\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Fear\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/text2emotion/__init__.py\u001b[0m in \u001b[0;36mcleaning\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m   2698\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2700\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memojis_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2701\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'http\\S+|www.\\S+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremoving_contradictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/text2emotion/__init__.py\u001b[0m in \u001b[0;36memojis_extractor\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m   2567\u001b[0m                             \u001b[0;34m'Fear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2568\u001b[0m                             'Fear']}\n\u001b[0;32m-> 2569\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNICODE_EMOJI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2570\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2571\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/text2emotion/__init__.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2567\u001b[0m                             \u001b[0;34m'Fear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2568\u001b[0m                             'Fear']}\n\u001b[0;32m-> 2569\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNICODE_EMOJI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2570\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2571\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'emoji' has no attribute 'UNICODE_EMOJI'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_to_df_ceo = pd.DataFrame(list_of_emotion_scores,columns= list_of_columns)\n",
        "print(list_to_df_ceo.head())\n",
        "df_ceo = pd.concat([df_ceo, list_to_df_ceo], axis=1)\n",
        "df_ceo.to_csv('/content/drive/MyDrive/ceoNN/CEO_Predicted.csv')"
      ],
      "metadata": {
        "id": "KPHBGKzH1JAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4296afa4-6af5-4236-b98c-eb859668c5ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Happy, Angry, Surprise, Sad, Fear]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_ceo.head(1000)"
      ],
      "metadata": {
        "id": "xGlC9b2jSgm7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "outputId": "325e110c-2aca-428d-9fab-310d70b79ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       username                   id                 date  \\\n",
              "0     @tim_cook  1200060640469159939  2019-11-28 14:35:27   \n",
              "1     @tim_cook  1200047686180835328  2019-11-28 13:43:58   \n",
              "2     @tim_cook  1199872990718169089  2019-11-28 02:09:48   \n",
              "3     @tim_cook  1199855397617704970  2019-11-28 00:59:53   \n",
              "4     @tim_cook  1199767313890922497  2019-11-27 19:09:52   \n",
              "..          ...                  ...                  ...   \n",
              "995  @BillGates  1150605518291001345  2019-07-15 03:18:27   \n",
              "996  @BillGates  1149722840847015942  2019-07-12 16:51:00   \n",
              "997  @BillGates  1149446129945366528  2019-07-11 22:31:27   \n",
              "998  @BillGates  1148674683883151360  2019-07-09 19:26:00   \n",
              "999  @BillGates  1146559254104616960  2019-07-03 23:20:02   \n",
              "\n",
              "                                                 tweet  retweets  likes  \\\n",
              "0    On this #Thanksgiving, I am reflecting on the ...       546   4434   \n",
              "1    Wishing everyone a #HappyThanksgiving filled w...       575   6097   \n",
              "2    Tomorrow the incredible @MNightShyamalan’s ser...       412   2607   \n",
              "3    Thanksgiving Day challenge! Close your rings w...       394   3932   \n",
              "4    As many of you travel to be with loved ones to...      1310   8436   \n",
              "..                                                 ...       ...    ...   \n",
              "995  I recently wrote about how people with tech sk...      1455   7274   \n",
              "996  “Fathers who help unlock their daughter’s pote...      3610  19731   \n",
              "997  Nearly one billion malaria cases have been pre...       789   4832   \n",
              "998  Can we feed 10 billion people? I’m optimistic ...      1798   9797   \n",
              "999  Nuclear power is the second-largest source of ...      2117   8107   \n",
              "\n",
              "                                   pre_processed_tweet  \\\n",
              "0    [on, thanksgiving, reflecting, dreamers, as, e...   \n",
              "1    [wishing, filled, joy, amp, happiness, reflect...   \n",
              "2    [tomorrow, incredible, mnightshyamalan, series...   \n",
              "3    [thanksgiving, day, challenge, close, rings, f...   \n",
              "4    [as, travel, loved, ones, today, remember, pre...   \n",
              "..                                                 ...   \n",
              "995  [recently, wrote, people, tech, skills, fascin...   \n",
              "996  [fathers, help, unlock, daughter, potential, s...   \n",
              "997  [nearly, billion, malaria, cases, prevented, i...   \n",
              "998  [can, feed, billion, people, optimistic, inves...   \n",
              "999  [nuclear, power, second, largest, source, low,...   \n",
              "\n",
              "             Class Probabilites  Predicted Classes  \n",
              "0    [2.767249e-06, 0.99999726]                  1  \n",
              "1       [0.38216636, 0.6178337]                  1  \n",
              "2    [0.9999733, 2.6653684e-05]                  0  \n",
              "3       [0.5591533, 0.44084668]                  0  \n",
              "4     [0.96569055, 0.034309506]                  0  \n",
              "..                          ...                ...  \n",
              "995     [0.05400344, 0.9459965]                  1  \n",
              "996    [0.49056494, 0.50943506]                  1  \n",
              "997    [0.59973973, 0.40026024]                  0  \n",
              "998     [0.19483748, 0.8051625]                  1  \n",
              "999     [0.5984351, 0.40156496]                  0  \n",
              "\n",
              "[1000 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b4b0c04-3e56-4448-962b-cb3db2158e21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>tweet</th>\n",
              "      <th>retweets</th>\n",
              "      <th>likes</th>\n",
              "      <th>pre_processed_tweet</th>\n",
              "      <th>Class Probabilites</th>\n",
              "      <th>Predicted Classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1200060640469159939</td>\n",
              "      <td>2019-11-28 14:35:27</td>\n",
              "      <td>On this #Thanksgiving, I am reflecting on the ...</td>\n",
              "      <td>546</td>\n",
              "      <td>4434</td>\n",
              "      <td>[on, thanksgiving, reflecting, dreamers, as, e...</td>\n",
              "      <td>[2.767249e-06, 0.99999726]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1200047686180835328</td>\n",
              "      <td>2019-11-28 13:43:58</td>\n",
              "      <td>Wishing everyone a #HappyThanksgiving filled w...</td>\n",
              "      <td>575</td>\n",
              "      <td>6097</td>\n",
              "      <td>[wishing, filled, joy, amp, happiness, reflect...</td>\n",
              "      <td>[0.38216636, 0.6178337]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1199872990718169089</td>\n",
              "      <td>2019-11-28 02:09:48</td>\n",
              "      <td>Tomorrow the incredible @MNightShyamalan’s ser...</td>\n",
              "      <td>412</td>\n",
              "      <td>2607</td>\n",
              "      <td>[tomorrow, incredible, mnightshyamalan, series...</td>\n",
              "      <td>[0.9999733, 2.6653684e-05]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1199855397617704970</td>\n",
              "      <td>2019-11-28 00:59:53</td>\n",
              "      <td>Thanksgiving Day challenge! Close your rings w...</td>\n",
              "      <td>394</td>\n",
              "      <td>3932</td>\n",
              "      <td>[thanksgiving, day, challenge, close, rings, f...</td>\n",
              "      <td>[0.5591533, 0.44084668]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1199767313890922497</td>\n",
              "      <td>2019-11-27 19:09:52</td>\n",
              "      <td>As many of you travel to be with loved ones to...</td>\n",
              "      <td>1310</td>\n",
              "      <td>8436</td>\n",
              "      <td>[as, travel, loved, ones, today, remember, pre...</td>\n",
              "      <td>[0.96569055, 0.034309506]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>@BillGates</td>\n",
              "      <td>1150605518291001345</td>\n",
              "      <td>2019-07-15 03:18:27</td>\n",
              "      <td>I recently wrote about how people with tech sk...</td>\n",
              "      <td>1455</td>\n",
              "      <td>7274</td>\n",
              "      <td>[recently, wrote, people, tech, skills, fascin...</td>\n",
              "      <td>[0.05400344, 0.9459965]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>@BillGates</td>\n",
              "      <td>1149722840847015942</td>\n",
              "      <td>2019-07-12 16:51:00</td>\n",
              "      <td>“Fathers who help unlock their daughter’s pote...</td>\n",
              "      <td>3610</td>\n",
              "      <td>19731</td>\n",
              "      <td>[fathers, help, unlock, daughter, potential, s...</td>\n",
              "      <td>[0.49056494, 0.50943506]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>@BillGates</td>\n",
              "      <td>1149446129945366528</td>\n",
              "      <td>2019-07-11 22:31:27</td>\n",
              "      <td>Nearly one billion malaria cases have been pre...</td>\n",
              "      <td>789</td>\n",
              "      <td>4832</td>\n",
              "      <td>[nearly, billion, malaria, cases, prevented, i...</td>\n",
              "      <td>[0.59973973, 0.40026024]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>@BillGates</td>\n",
              "      <td>1148674683883151360</td>\n",
              "      <td>2019-07-09 19:26:00</td>\n",
              "      <td>Can we feed 10 billion people? I’m optimistic ...</td>\n",
              "      <td>1798</td>\n",
              "      <td>9797</td>\n",
              "      <td>[can, feed, billion, people, optimistic, inves...</td>\n",
              "      <td>[0.19483748, 0.8051625]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>@BillGates</td>\n",
              "      <td>1146559254104616960</td>\n",
              "      <td>2019-07-03 23:20:02</td>\n",
              "      <td>Nuclear power is the second-largest source of ...</td>\n",
              "      <td>2117</td>\n",
              "      <td>8107</td>\n",
              "      <td>[nuclear, power, second, largest, source, low,...</td>\n",
              "      <td>[0.5984351, 0.40156496]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b4b0c04-3e56-4448-962b-cb3db2158e21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b4b0c04-3e56-4448-962b-cb3db2158e21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b4b0c04-3e56-4448-962b-cb3db2158e21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ceo_predicted = pd.read_csv('/content/drive/MyDrive/ceoNN/CEO_Predicted.csv')\n"
      ],
      "metadata": {
        "id": "U-OBpVrzqLyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_predicted_probabilities = pd.DataFrame(test_ceo_results,columns=['Republican', 'Democrate'])"
      ],
      "metadata": {
        "id": "JglqeSIxqmCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_ceo_predicted = pd.concat([ceo_predicted, dataframe_predicted_probabilities], axis=1)\n",
        "dataframe_ceo_predicted.to_csv('/content/drive/MyDrive/ceoNN/CEO_Predicted_v1.csv')"
      ],
      "metadata": {
        "id": "5AORp6zzq5fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_ceo_predicted.head(19)"
      ],
      "metadata": {
        "id": "lG_9FRMXruue",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "44ac3c5d-9a9b-44df-d687-2a36e6ebfa55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0   username                   id                 date  \\\n",
              "0            0  @tim_cook  1200060640469159939  2019-11-28 14:35:27   \n",
              "1            1  @tim_cook  1200047686180835328  2019-11-28 13:43:58   \n",
              "2            2  @tim_cook  1199872990718169089  2019-11-28 02:09:48   \n",
              "3            3  @tim_cook  1199855397617704970  2019-11-28 00:59:53   \n",
              "4            4  @tim_cook  1199767313890922497  2019-11-27 19:09:52   \n",
              "5            5  @tim_cook  1197141315064086530  2019-11-20 13:15:05   \n",
              "6            6  @tim_cook  1196927442906013696  2019-11-19 23:05:14   \n",
              "7            7  @tim_cook  1196914279967903744  2019-11-19 22:12:56   \n",
              "8            8  @tim_cook  1195833226972913664  2019-11-16 22:37:13   \n",
              "9            9  @tim_cook  1195399185815572480  2019-11-15 17:52:29   \n",
              "10          10  @tim_cook  1195073339393314818  2019-11-14 20:17:42   \n",
              "11          11  @tim_cook  1194985641148182528  2019-11-14 14:29:13   \n",
              "12          12  @tim_cook  1194614812195442688  2019-11-13 13:55:40   \n",
              "13          13  @tim_cook  1194607635590332416  2019-11-13 13:27:09   \n",
              "14          14  @tim_cook  1193879150357925889  2019-11-11 13:12:25   \n",
              "15          15  @tim_cook  1193167038555967489  2019-11-09 14:02:44   \n",
              "16          16  @tim_cook  1193024107886956544  2019-11-09 04:34:47   \n",
              "17          17  @tim_cook  1192934331330646017  2019-11-08 22:38:02   \n",
              "18          18  @tim_cook  1192863702493515776  2019-11-08 17:57:23   \n",
              "\n",
              "                                                tweet  retweets  likes  \\\n",
              "0   On this #Thanksgiving, I am reflecting on the ...       546   4434   \n",
              "1   Wishing everyone a #HappyThanksgiving filled w...       575   6097   \n",
              "2   Tomorrow the incredible @MNightShyamalan’s ser...       412   2607   \n",
              "3   Thanksgiving Day challenge! Close your rings w...       394   3932   \n",
              "4   As many of you travel to be with loved ones to...      1310   8436   \n",
              "5   The construction of our new Austin campus is u...      3804  23155   \n",
              "6   It’s incredible to see how Salesforce and thei...       611   4750   \n",
              "7   Love this look at Chicago through the eyes of ...       200   2185   \n",
              "8   We’re proud to team up with @TSUedu and @nc100...       219   1866   \n",
              "9   “The innovation of Night mode is incredible! I...       757   6827   \n",
              "10  Our hearts are broken for the students, parent...       605   6004   \n",
              "11  The Research app is a game changer. Participan...       775   4626   \n",
              "12  We’re inspired by the things pro customers cre...      2685  14180   \n",
              "13  Pros — you asked for it. And it’s here. https:...      4174  21409   \n",
              "14  \"Never was so much owed by so many to so few.\"...       644   6096   \n",
              "15  Thirty years after the Berlin Wall fell, we mu...      1799  12457   \n",
              "16  Joe, you are a creative force and an important...       209   1942   \n",
              "17  It was an honor to celebrate the Veterans in o...       313   4450   \n",
              "18  Thanks @Oprah! It’s one of my favorite things ...       351   4340   \n",
              "\n",
              "                                  pre_processed_tweet  \\\n",
              "0   ['on', 'thanksgiving', 'reflecting', 'dreamers...   \n",
              "1   ['wishing', 'filled', 'joy', 'amp', 'happiness...   \n",
              "2   ['tomorrow', 'incredible', 'mnightshyamalan', ...   \n",
              "3   ['thanksgiving', 'day', 'challenge', 'close', ...   \n",
              "4   ['as', 'travel', 'loved', 'ones', 'today', 're...   \n",
              "5   ['the', 'construction', 'new', 'austin', 'camp...   \n",
              "6   ['it', 'incredible', 'salesforce', 'passionate...   \n",
              "7   ['love', 'look', 'chicago', 'eyes', 'students'...   \n",
              "8   ['we', 're', 'proud', 'team', 'tsuedu', 'nc', ...   \n",
              "9   ['the', 'innovation', 'night', 'mode', 'incred...   \n",
              "10  ['our', 'hearts', 'broken', 'students', 'paren...   \n",
              "11  ['the', 'research', 'app', 'game', 'changer', ...   \n",
              "12  ['we', 're', 'inspired', 'things', 'pro', 'cus...   \n",
              "13  ['pros', 'asked', 'it', 'and', 'it', 'here', '...   \n",
              "14  ['never', 'owed', 'few', 'winston', 'churchill...   \n",
              "15  ['thirty', 'years', 'berlin', 'wall', 'fell', ...   \n",
              "16  ['joe', 'creative', 'force', 'important', 'voi...   \n",
              "17  ['it', 'honor', 'celebrate', 'veterans', 'appl...   \n",
              "18  ['thanks', 'oprah', 'it', 'favorite', 'things'...   \n",
              "\n",
              "               Class Probabilites  Predicted Classes  Happy  Angry  Surprise  \\\n",
              "0   [2.7672490e-06 9.9999726e-01]                  1    NaN    NaN       NaN   \n",
              "1         [0.38216636 0.6178337 ]                  1    NaN    NaN       NaN   \n",
              "2   [9.9997330e-01 2.6653684e-05]                  0    NaN    NaN       NaN   \n",
              "3         [0.5591533  0.44084668]                  0    NaN    NaN       NaN   \n",
              "4         [0.96569055 0.03430951]                  0    NaN    NaN       NaN   \n",
              "5         [0.00164084 0.99835914]                  1    NaN    NaN       NaN   \n",
              "6         [0.46936738 0.53063256]                  1    NaN    NaN       NaN   \n",
              "7         [0.00212858 0.9978714 ]                  1    NaN    NaN       NaN   \n",
              "8   [7.0226152e-04 9.9929774e-01]                  1    NaN    NaN       NaN   \n",
              "9           [0.4870891 0.5129109]                  1    NaN    NaN       NaN   \n",
              "10        [0.79401493 0.20598505]                  0    NaN    NaN       NaN   \n",
              "11        [0.5383598  0.46164018]                  0    NaN    NaN       NaN   \n",
              "12        [0.99441385 0.00558614]                  0    NaN    NaN       NaN   \n",
              "13        [0.46142596 0.53857404]                  1    NaN    NaN       NaN   \n",
              "14        [0.9855458  0.01445418]                  0    NaN    NaN       NaN   \n",
              "15        [0.5360842  0.46391582]                  0    NaN    NaN       NaN   \n",
              "16        [0.9582074  0.04179253]                  0    NaN    NaN       NaN   \n",
              "17    [9.997800e-01 2.200631e-04]                  0    NaN    NaN       NaN   \n",
              "18        [0.45937088 0.54062915]                  1    NaN    NaN       NaN   \n",
              "\n",
              "    Sad  Fear  Republican  Democrate  \n",
              "0   NaN   NaN    0.000003   0.999997  \n",
              "1   NaN   NaN    0.382166   0.617834  \n",
              "2   NaN   NaN    0.999973   0.000027  \n",
              "3   NaN   NaN    0.559153   0.440847  \n",
              "4   NaN   NaN    0.965691   0.034310  \n",
              "5   NaN   NaN    0.001641   0.998359  \n",
              "6   NaN   NaN    0.469367   0.530633  \n",
              "7   NaN   NaN    0.002129   0.997871  \n",
              "8   NaN   NaN    0.000702   0.999298  \n",
              "9   NaN   NaN    0.487089   0.512911  \n",
              "10  NaN   NaN    0.794015   0.205985  \n",
              "11  NaN   NaN    0.538360   0.461640  \n",
              "12  NaN   NaN    0.994414   0.005586  \n",
              "13  NaN   NaN    0.461426   0.538574  \n",
              "14  NaN   NaN    0.985546   0.014454  \n",
              "15  NaN   NaN    0.536084   0.463916  \n",
              "16  NaN   NaN    0.958207   0.041793  \n",
              "17  NaN   NaN    0.999780   0.000220  \n",
              "18  NaN   NaN    0.459371   0.540629  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec6c37d4-55cb-463d-aaf3-528e50f6684f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>username</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>tweet</th>\n",
              "      <th>retweets</th>\n",
              "      <th>likes</th>\n",
              "      <th>pre_processed_tweet</th>\n",
              "      <th>Class Probabilites</th>\n",
              "      <th>Predicted Classes</th>\n",
              "      <th>Happy</th>\n",
              "      <th>Angry</th>\n",
              "      <th>Surprise</th>\n",
              "      <th>Sad</th>\n",
              "      <th>Fear</th>\n",
              "      <th>Republican</th>\n",
              "      <th>Democrate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1200060640469159939</td>\n",
              "      <td>2019-11-28 14:35:27</td>\n",
              "      <td>On this #Thanksgiving, I am reflecting on the ...</td>\n",
              "      <td>546</td>\n",
              "      <td>4434</td>\n",
              "      <td>['on', 'thanksgiving', 'reflecting', 'dreamers...</td>\n",
              "      <td>[2.7672490e-06 9.9999726e-01]</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.999997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1200047686180835328</td>\n",
              "      <td>2019-11-28 13:43:58</td>\n",
              "      <td>Wishing everyone a #HappyThanksgiving filled w...</td>\n",
              "      <td>575</td>\n",
              "      <td>6097</td>\n",
              "      <td>['wishing', 'filled', 'joy', 'amp', 'happiness...</td>\n",
              "      <td>[0.38216636 0.6178337 ]</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.382166</td>\n",
              "      <td>0.617834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1199872990718169089</td>\n",
              "      <td>2019-11-28 02:09:48</td>\n",
              "      <td>Tomorrow the incredible @MNightShyamalan’s ser...</td>\n",
              "      <td>412</td>\n",
              "      <td>2607</td>\n",
              "      <td>['tomorrow', 'incredible', 'mnightshyamalan', ...</td>\n",
              "      <td>[9.9997330e-01 2.6653684e-05]</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.999973</td>\n",
              "      <td>0.000027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1199855397617704970</td>\n",
              "      <td>2019-11-28 00:59:53</td>\n",
              "      <td>Thanksgiving Day challenge! Close your rings w...</td>\n",
              "      <td>394</td>\n",
              "      <td>3932</td>\n",
              "      <td>['thanksgiving', 'day', 'challenge', 'close', ...</td>\n",
              "      <td>[0.5591533  0.44084668]</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.559153</td>\n",
              "      <td>0.440847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1199767313890922497</td>\n",
              "      <td>2019-11-27 19:09:52</td>\n",
              "      <td>As many of you travel to be with loved ones to...</td>\n",
              "      <td>1310</td>\n",
              "      <td>8436</td>\n",
              "      <td>['as', 'travel', 'loved', 'ones', 'today', 're...</td>\n",
              "      <td>[0.96569055 0.03430951]</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.965691</td>\n",
              "      <td>0.034310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1197141315064086530</td>\n",
              "      <td>2019-11-20 13:15:05</td>\n",
              "      <td>The construction of our new Austin campus is u...</td>\n",
              "      <td>3804</td>\n",
              "      <td>23155</td>\n",
              "      <td>['the', 'construction', 'new', 'austin', 'camp...</td>\n",
              "      <td>[0.00164084 0.99835914]</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001641</td>\n",
              "      <td>0.998359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1196927442906013696</td>\n",
              "      <td>2019-11-19 23:05:14</td>\n",
              "      <td>It’s incredible to see how Salesforce and thei...</td>\n",
              "      <td>611</td>\n",
              "      <td>4750</td>\n",
              "      <td>['it', 'incredible', 'salesforce', 'passionate...</td>\n",
              "      <td>[0.46936738 0.53063256]</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.469367</td>\n",
              "      <td>0.530633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1196914279967903744</td>\n",
              "      <td>2019-11-19 22:12:56</td>\n",
              "      <td>Love this look at Chicago through the eyes of ...</td>\n",
              "      <td>200</td>\n",
              "      <td>2185</td>\n",
              "      <td>['love', 'look', 'chicago', 'eyes', 'students'...</td>\n",
              "      <td>[0.00212858 0.9978714 ]</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.002129</td>\n",
              "      <td>0.997871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1195833226972913664</td>\n",
              "      <td>2019-11-16 22:37:13</td>\n",
              "      <td>We’re proud to team up with @TSUedu and @nc100...</td>\n",
              "      <td>219</td>\n",
              "      <td>1866</td>\n",
              "      <td>['we', 're', 'proud', 'team', 'tsuedu', 'nc', ...</td>\n",
              "      <td>[7.0226152e-04 9.9929774e-01]</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000702</td>\n",
              "      <td>0.999298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1195399185815572480</td>\n",
              "      <td>2019-11-15 17:52:29</td>\n",
              "      <td>“The innovation of Night mode is incredible! I...</td>\n",
              "      <td>757</td>\n",
              "      <td>6827</td>\n",
              "      <td>['the', 'innovation', 'night', 'mode', 'incred...</td>\n",
              "      <td>[0.4870891 0.5129109]</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.487089</td>\n",
              "      <td>0.512911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1195073339393314818</td>\n",
              "      <td>2019-11-14 20:17:42</td>\n",
              "      <td>Our hearts are broken for the students, parent...</td>\n",
              "      <td>605</td>\n",
              "      <td>6004</td>\n",
              "      <td>['our', 'hearts', 'broken', 'students', 'paren...</td>\n",
              "      <td>[0.79401493 0.20598505]</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.794015</td>\n",
              "      <td>0.205985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1194985641148182528</td>\n",
              "      <td>2019-11-14 14:29:13</td>\n",
              "      <td>The Research app is a game changer. Participan...</td>\n",
              "      <td>775</td>\n",
              "      <td>4626</td>\n",
              "      <td>['the', 'research', 'app', 'game', 'changer', ...</td>\n",
              "      <td>[0.5383598  0.46164018]</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.538360</td>\n",
              "      <td>0.461640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1194614812195442688</td>\n",
              "      <td>2019-11-13 13:55:40</td>\n",
              "      <td>We’re inspired by the things pro customers cre...</td>\n",
              "      <td>2685</td>\n",
              "      <td>14180</td>\n",
              "      <td>['we', 're', 'inspired', 'things', 'pro', 'cus...</td>\n",
              "      <td>[0.99441385 0.00558614]</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.994414</td>\n",
              "      <td>0.005586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1194607635590332416</td>\n",
              "      <td>2019-11-13 13:27:09</td>\n",
              "      <td>Pros — you asked for it. And it’s here. https:...</td>\n",
              "      <td>4174</td>\n",
              "      <td>21409</td>\n",
              "      <td>['pros', 'asked', 'it', 'and', 'it', 'here', '...</td>\n",
              "      <td>[0.46142596 0.53857404]</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.461426</td>\n",
              "      <td>0.538574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1193879150357925889</td>\n",
              "      <td>2019-11-11 13:12:25</td>\n",
              "      <td>\"Never was so much owed by so many to so few.\"...</td>\n",
              "      <td>644</td>\n",
              "      <td>6096</td>\n",
              "      <td>['never', 'owed', 'few', 'winston', 'churchill...</td>\n",
              "      <td>[0.9855458  0.01445418]</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.985546</td>\n",
              "      <td>0.014454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1193167038555967489</td>\n",
              "      <td>2019-11-09 14:02:44</td>\n",
              "      <td>Thirty years after the Berlin Wall fell, we mu...</td>\n",
              "      <td>1799</td>\n",
              "      <td>12457</td>\n",
              "      <td>['thirty', 'years', 'berlin', 'wall', 'fell', ...</td>\n",
              "      <td>[0.5360842  0.46391582]</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.536084</td>\n",
              "      <td>0.463916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1193024107886956544</td>\n",
              "      <td>2019-11-09 04:34:47</td>\n",
              "      <td>Joe, you are a creative force and an important...</td>\n",
              "      <td>209</td>\n",
              "      <td>1942</td>\n",
              "      <td>['joe', 'creative', 'force', 'important', 'voi...</td>\n",
              "      <td>[0.9582074  0.04179253]</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.958207</td>\n",
              "      <td>0.041793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1192934331330646017</td>\n",
              "      <td>2019-11-08 22:38:02</td>\n",
              "      <td>It was an honor to celebrate the Veterans in o...</td>\n",
              "      <td>313</td>\n",
              "      <td>4450</td>\n",
              "      <td>['it', 'honor', 'celebrate', 'veterans', 'appl...</td>\n",
              "      <td>[9.997800e-01 2.200631e-04]</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.999780</td>\n",
              "      <td>0.000220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>@tim_cook</td>\n",
              "      <td>1192863702493515776</td>\n",
              "      <td>2019-11-08 17:57:23</td>\n",
              "      <td>Thanks @Oprah! It’s one of my favorite things ...</td>\n",
              "      <td>351</td>\n",
              "      <td>4340</td>\n",
              "      <td>['thanks', 'oprah', 'it', 'favorite', 'things'...</td>\n",
              "      <td>[0.45937088 0.54062915]</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.459371</td>\n",
              "      <td>0.540629</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec6c37d4-55cb-463d-aaf3-528e50f6684f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec6c37d4-55cb-463d-aaf3-528e50f6684f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec6c37d4-55cb-463d-aaf3-528e50f6684f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}